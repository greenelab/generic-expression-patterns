{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulate gene expression data\n",
    "\n",
    "This notebook simulates gene expression data that can then be plugged into different enrichment methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext rpy2.ipython\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "\n",
    "from ponyo import utils, simulate_expression_data\n",
    "from generic_expression_patterns_modules import process, stats, ranking\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config variables\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "config_filename = os.path.abspath(\n",
    "    os.path.join(base_dir, \"configs\", \"config_human_general.tsv\")\n",
    ")\n",
    "\n",
    "params = utils.read_config(config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params['dataset_name']\n",
    "NN_architecture = params['NN_architecture']\n",
    "num_runs = params['num_simulated']\n",
    "project_id = params['project_id']\n",
    "metadata_col_id = params['metadata_colname']\n",
    "mapped_template_filename = params['mapped_template_filename']\n",
    "processed_template_filename = params['processed_template_filename']\n",
    "normalized_compendium_filename = params['normalized_compendium_filename']\n",
    "scaler_filename = params['scaler_filename']\n",
    "col_to_rank_genes = params['rank_genes_by']\n",
    "col_to_rank_pathways = params['rank_pathways_by']\n",
    "statistic = params['gsea_statistic']\n",
    "count_threshold = params['count_threshold']\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "sample_id_metadata_filename = os.path.join(\n",
    "    base_dir,\n",
    "    dataset_name,\n",
    "    \"data\",\n",
    "    \"metadata\",\n",
    "    f\"{project_id}_process_samples.tsv\"\n",
    ")\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "metadata_filename = os.path.join(\n",
    "    base_dir,\n",
    "    dataset_name,\n",
    "    \"data\",\n",
    "    \"metadata\",\n",
    "    f\"{project_id}_groups.tsv\"\n",
    ")\n",
    "\n",
    "# Load pickled file\n",
    "with open(scaler_filename, \"rb\") as scaler_fh:\n",
    "    scaler = pickle.load(scaler_fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "gene_summary_filename = os.path.join(\n",
    "    base_dir, \n",
    "    dataset_name, \n",
    "    f\"generic_gene_summary_{project_id}.tsv\"\n",
    ")\n",
    "\n",
    "pathway_summary_filename = os.path.join(\n",
    "    base_dir, \n",
    "    dataset_name, \n",
    "    f\"generic_pathway_summary_{project_id}.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate experiments using selected template experiment\n",
    "\n",
    "Workflow:\n",
    "\n",
    "1. Get the gene expression data for the selected template experiment\n",
    "2. Encode this experiment into a latent space using the trained VAE model\n",
    "3. Linearly shift the encoded template experiment in the latent space\n",
    "4. Decode the samples. This results in a new experiment\n",
    "5. Repeat steps 1-4 to get multiple simulated experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate multiple experiments\n",
    "# This step creates the following files in \"<local_dir>/pseudo_experiment/\" directory:           \n",
    "#   - selected_simulated_data_SRP012656_<n>.txt\n",
    "#   - selected_simulated_encoded_data_SRP012656_<n>.txt\n",
    "#   - template_normalized_data_SRP012656_test.txt\n",
    "# in which \"<n>\" is an integer in the range of [0, num_runs-1] \n",
    "os.makedirs(os.path.join(local_dir, \"pseudo_experiment\"), exist_ok=True)\n",
    "for run_id in range(num_runs):\n",
    "    simulate_expression_data.shift_template_experiment(\n",
    "        normalized_compendium_filename,\n",
    "        project_id,\n",
    "        metadata_col_id,\n",
    "        NN_architecture,\n",
    "        dataset_name,\n",
    "        scaler,\n",
    "        local_dir,\n",
    "        base_dir,\n",
    "        run_id\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process template and simulated experiments\n",
    "\n",
    "* Remove samples not required for comparison\n",
    "* Make sure ordering of samples matches metadata for proper comparison\n",
    "* Make sure values are cast as integers for using DESeq\n",
    "* Filter lowly expressed genes for using DESeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(sample_id_metadata_filename):\n",
    "    sample_id_metadata_filename = None\n",
    "    \n",
    "stats.process_samples_for_DESeq(\n",
    "        mapped_template_filename,\n",
    "        metadata_filename,\n",
    "        processed_template_filename,\n",
    "        count_threshold,\n",
    "        sample_id_metadata_filename,\n",
    "    )\n",
    "\n",
    "for i in range(num_runs):\n",
    "    simulated_filename = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        f\"selected_simulated_data_{project_id}_{i}.txt\"\n",
    "    )\n",
    "    out_simulated_filename = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        f\"selected_simulated_data_{project_id}_{i}_processed.txt\"\n",
    "    )\n",
    "    stats.process_samples_for_DESeq(\n",
    "        simulated_filename,\n",
    "        metadata_filename,\n",
    "        out_simulated_filename,\n",
    "        count_threshold,\n",
    "        sample_id_metadata_filename,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:generic_expression] *",
   "language": "python",
   "name": "conda-env-generic_expression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
