{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process recount2 data\n",
    "This notebook does the following:\n",
    "\n",
    "1. Selects template experiment\n",
    "2. Downloads subset of recount2 data, including the template experiment (subset of random experiments + 1 template experiment)\n",
    "3. Train VAE on subset of recount2 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression_PYTEST/lib/python3.7/site-packages/ponyo/helper_vae.py:21: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression_PYTEST/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression_PYTEST/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alexandra/anaconda3/envs/generic_expression_PYTEST/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext rpy2.ipython\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from ponyo import utils, train_vae_modules\n",
    "from generic_expression_patterns_modules import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/Documents/Repos/generic-expression-patterns/generic_expression_patterns_modules/process.py:57: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seeds to get reproducible VAE trained models\n",
    "process.set_all_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "# Read in config variables\n",
    "config_filename = os.path.abspath(os.path.join(base_dir, \"configs\", \"config_test.tsv\"))\n",
    "\n",
    "params = utils.read_config(config_filename)\n",
    "\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params[\"dataset_name\"]\n",
    "\n",
    "# File that contains gene ranks identified by Crow et. al.\n",
    "DE_prior_filename = params[\"reference_gene_filename\"]\n",
    "\n",
    "# Template experiment ID\n",
    "project_id = params[\"project_id\"]\n",
    "\n",
    "# Output file: pickled list of shared genes(generated during gene ID mapping)\n",
    "shared_genes_filename = params[\"shared_genes_filename\"]\n",
    "\n",
    "# Output files of recount2 template experiment data\n",
    "raw_template_filename = params[\"raw_template_filename\"]\n",
    "mapped_template_filename = params[\"mapped_template_filename\"]\n",
    "\n",
    "# Output files of recount2 compendium data\n",
    "raw_compendium_filename = params[\"raw_compendium_filename\"]\n",
    "mapped_compendium_filename = params[\"mapped_compendium_filename\"]\n",
    "normalized_compendium_filename = params[\"normalized_compendium_filename\"]\n",
    "\n",
    "# Output file: pickled scaler (generated during compendium normalization)\n",
    "scaler_filename = params[\"scaler_filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(\"data/input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where the downloaded files of template experiment will be saved into\n",
    "template_download_dir = os.path.join(local_dir, \"template_download\")\n",
    "\n",
    "# Make sure this directory already exists\n",
    "os.makedirs(template_download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.exists(template_download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: 2021-04-27 13:38:11 downloading file rse_gene.Rdata to Generic_expression_patterns_test/template_download/SRP012656\n",
      "\n",
      "R[write to console]: trying URL 'http://duffel.rail.bio/recount/v2/SRP012656/rse_gene.Rdata'\n",
      "\n",
      "R[write to console]: Content type 'application/octet-stream'\n",
      "R[write to console]:  length 5841450 bytes (5.6 MB)\n",
      "\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: =\n",
      "R[write to console]: \n",
      "\n",
      "R[write to console]: downloaded 5.6 MB\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading objects:\n",
      "  rse_gene\n"
     ]
    }
   ],
   "source": [
    "%%R -i project_id -i template_download_dir -i raw_template_filename -i base_dir\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/download_recount2_data.R'))\n",
    "\n",
    "get_recount2_template_experiment(project_id, template_download_dir, raw_template_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-53dedeaf9dca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_template_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert os.path.exists(raw_template_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Renaming gene ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File mapping ensembl ids to hgnc symbols\n",
    "gene_id_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", \"ensembl_hgnc_mapping.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i raw_template_filename -i gene_id_filename -i base_dir\n",
    "\n",
    "# Get mapping between ensembl gene ids (ours) to HGNC gene symbols (published)\n",
    "# Input: raw_template_filename, output: gene_id_filename\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/process_names.R'))\n",
    "\n",
    "# Note: This mapping file from ensembl ids to hgnc symbols is based on the library(\"biomaRt\")\n",
    "# that gets updated. In order to get the most up-to-date version, you can delete the\n",
    "# ensembl_hgnc_mapping file to re-run the script that generates this mapping.\n",
    "\n",
    "if (file.exists(gene_id_filename) == FALSE) {\n",
    "    get_ensembl_symbol_mapping(raw_template_filename, gene_id_filename)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: processing template data\n",
    "This step will map the ensembl gene IDs in raw template data file to hgnc gene symbols, and delete certain columns (genes) and rows (samples).\n",
    "\n",
    "Output files generated in this step:\n",
    "- `shared_genes_filename`: pickled list of shared genes (created only if it doesn't exist yet)\n",
    "- `mapped_template_filename`: template data with column names mapped to hgnc gene symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_mapping = {\n",
    "    \"ENSG00000187510.7\": \"PLEKHG7\",\n",
    "    \"ENSG00000230417.11\": \"LINC00595\",\n",
    "    \"ENSG00000276085.1\": \"CCL3L1\",\n",
    "    \"ENSG00000255374.3\": \"TAS2R45\",\n",
    "}\n",
    "\n",
    "process.map_recount2_data(\n",
    "    raw_template_filename,\n",
    "    gene_id_filename,\n",
    "    manual_mapping,\n",
    "    DE_prior_filename,\n",
    "    shared_genes_filename,\n",
    "    mapped_template_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test: Processing compendium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.process_raw_compendium_recount2(\n",
    "    raw_compendium_filename,\n",
    "    gene_id_filename,\n",
    "    manual_mapping,\n",
    "    DE_prior_filename,\n",
    "    shared_genes_filename,\n",
    "    mapped_compendium_filename,\n",
    "    normalized_compendium_filename,\n",
    "    scaler_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of genes is equal between the compendium and the template\n",
    "compendium_data = pd.read_csv(\n",
    "    normalized_compendium_filename, sep=\"\\t\", index_col=0, header=0\n",
    ")\n",
    "\n",
    "template_data = pd.read_csv(mapped_template_filename, header=0, sep=\"\\t\", index_col=0)\n",
    "assert compendium_data.shape[1] == template_data.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train: VAE training and reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE directories\n",
    "output_dirs = [\n",
    "    os.path.join(base_dir, dataset_name, \"models\"),\n",
    "    os.path.join(base_dir, dataset_name, \"logs\"),\n",
    "]\n",
    "NN_architecture = params[\"NN_architecture\"]\n",
    "\n",
    "for each_dir in output_dirs:\n",
    "    new_dir = os.path.join(each_dir, NN_architecture)\n",
    "    os.makedirs(new_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VAE on new compendium data\n",
    "train_vae_modules.train_vae(config_filename, normalized_compendium_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test reproducibility\n",
    "expected_log = \"data/test_vae_logs.tsv\"\n",
    "actual_log = \"logs/NN_2500_30/tybalt_2layer_30latent_stats.tsv\"\n",
    "assert pd.read_csv(actual_log, sep=\"\\t\")[\"val_loss\"].values[-1] < 15000, pd.read_csv(\n",
    "    actual_log, sep=\"\\t\"\n",
    ")[\"val_loss\"].values[-1]"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1592246126078,
   "trusted": true
  },
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:generic_expression_PYTEST] *",
   "language": "python",
   "name": "conda-env-generic_expression_PYTEST-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
