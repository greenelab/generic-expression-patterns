{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify generic genes and pathways\n",
    "\n",
    "Studies have found that some genes are more likely to be differentially expressed even across a wide range of experimental designs. These generic genes and subsequent pathways are not necessarily specific to the biological process being studied but instead represent a more systematic change.\n",
    "\n",
    "This notebook identifies generic genes and pathways and then evaluates if those identified are consistent with published findings.\n",
    "\n",
    "**Steps to identify generic genes:**\n",
    "1. Simulates N gene expression experiments using [ponyo](https://github.com/ajlee21/ponyo)\n",
    "2. Perform DE analysis to get association statistics for each gene\n",
    "3. For each gene, aggregate statsitics across all simulated experiments\n",
    "4. Rank genes based on this aggregated statistic (i.e. log fold change, or p-value)\n",
    "\n",
    "\n",
    "**Steps to identify generic gene sets (pathways):**\n",
    "1. Using the same simulated experiments from above, perform GSEA analysis. This analysis will determine whether the genes contained in a gene set are clustered towards the beginning or the end of the ranked list of genes, where genes are ranked by log fold change, indicating a correlation with change in expression.\n",
    "2. For each gene set (pathway), aggregate statistics across all simulated experiments\n",
    "3. Rank gene sets based on this aggregated statistic\n",
    "\n",
    "**Evaluation:**\n",
    "* We want to compare the ranking of genes identified using the above method with the ranking found from [Crow et. al.](https://www.pnas.org/content/pnas/116/13/6491.full.pdf), which identified a set of genes as generic based on how frequently they were found to be DE across 600 experiments\n",
    "* We want to compare the ranking of pathways identified using the above method with the ranking based on the [Powers et. al.](https://www.biorxiv.org/content/10.1101/259440v1.full.pdf) data, where ranking was determined based on the fraction of 442 experiments a pathway was found to be enriched\n",
    "* This comparison will validate our method being used as a way to automatically identify generic genes and pathways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%load_ext rpy2.ipython\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import glob\n",
    "import scipy.stats as ss\n",
    "from keras.models import load_model\n",
    "from rpy2.robjects import pandas2ri\n",
    "from ponyo import utils\n",
    "from generic_expression_patterns_modules import process, stats, ranking\n",
    "\n",
    "pandas2ri.activate()\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in config variables\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "config_filename = os.path.abspath(\n",
    "    os.path.join(base_dir, \"configs\", \"config_human_Crow.tsv\")\n",
    ")\n",
    "\n",
    "params = utils.read_config(config_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load params\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params[\"dataset_name\"]\n",
    "NN_architecture = params[\"NN_architecture\"]\n",
    "num_runs = params[\"num_simulated\"]\n",
    "project_id = params[\"project_id\"]\n",
    "metadata_col_id = params[\"metadata_colname\"]\n",
    "mapped_template_filename = params[\"mapped_template_filename\"]\n",
    "processed_template_filename = params[\"processed_template_filename\"]\n",
    "normalized_compendium_filename = params[\"normalized_compendium_filename\"]\n",
    "scaler_filename = params[\"scaler_filename\"]\n",
    "col_to_rank_genes = params[\"rank_genes_by\"]\n",
    "col_to_rank_pathways = params[\"rank_pathways_by\"]\n",
    "statistic = params[\"gsea_statistic\"]\n",
    "logFC_name = params[\"DE_logFC_name\"]\n",
    "pvalue_name = params[\"DE_pvalue_name\"]\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "sample_id_metadata_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", f\"{project_id}_process_samples.tsv\"\n",
    ")\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "grp_metadata_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", f\"{project_id}_groups.tsv\"\n",
    ")\n",
    "\n",
    "# Load pickled file\n",
    "with open(scaler_filename, \"rb\") as scaler_fh:\n",
    "    scaler = pickle.load(scaler_fh)\n",
    "\n",
    "# Percentile threshold to identify generic genes\n",
    "percentile_threshold = 80.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output files\n",
    "gene_summary_filename = os.path.join(\n",
    "    base_dir, dataset_name, f\"generic_gene_summary_{project_id}.tsv\"\n",
    ")\n",
    "\n",
    "pathway_summary_filename = os.path.join(\n",
    "    base_dir, dataset_name, f\"generic_pathway_summary_{project_id}.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need to customize code from ponyo\n",
    "\n",
    "The current simulation-related function in ponyo, `get_sample_ids` assumes that the user is using one of two different metadata files (one associated with the pseudomonas compendium and another associated with recount2). The compendium dataset we are using here has a slightly different format for their metadata file.\n",
    "\n",
    "Here we are temporarily writing our own function customized for this Powers et. al. dataset. But we will be updating ponyo to allow for different metadata files in the future. Issue in ponyo is [here](https://github.com/greenelab/ponyo/issues/18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_ids(experiment_id, dataset_name, sample_id_colname):\n",
    "    \"\"\"\n",
    "    Returns sample ids (found in gene expression df) associated with\n",
    "    a given list of experiment ids (found in the metadata)\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    experiment_ids_file: str\n",
    "        File containing all cleaned experiment ids\n",
    "\n",
    "    dataset_name: str\n",
    "        Name for analysis directory. Either \"Human\" or \"Pseudomonas\"\n",
    "\n",
    "    sample_id_colname: str\n",
    "        Column header that contains sample id that maps expression data\n",
    "        and metadata\n",
    "\n",
    "    \"\"\"\n",
    "    # Read in metadata\n",
    "    metadata = pd.read_csv(metadata_filename, header=0)\n",
    "    metadata.set_index(\"Experiment id\", inplace=True)\n",
    "\n",
    "    selected_metadata = metadata.loc[experiment_id]\n",
    "    sample_ids = list(selected_metadata[sample_id_colname])\n",
    "\n",
    "    return sample_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_template_experiment_with_metadatafile(\n",
    "    normalized_data_file,\n",
    "    selected_experiment_id,\n",
    "    sample_id_colname,\n",
    "    NN_architecture,\n",
    "    dataset_name,\n",
    "    scaler,\n",
    "    local_dir,\n",
    "    base_dir,\n",
    "    run,\n",
    "    metadata_filename,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate new simulated experiment using the selected_experiment_id as a template\n",
    "    experiment using the same workflow as `simulate_by_latent_transform`\n",
    "\n",
    "    This will return a file with a single simulated experiment following the workflow mentioned.\n",
    "    This function can be run multiple times to generate multiple simulated experiments from a\n",
    "    single selected_experiment_id.\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    normalized_data_file: str\n",
    "        File containing normalized gene expression data\n",
    "\n",
    "        ------------------------------| PA0001 | PA0002 |...\n",
    "        05_PA14000-4-2_5-10-07_S2.CEL | 0.8533 | 0.7252 |...\n",
    "        54375-4-05.CEL                | 0.7789 | 0.7678 |...\n",
    "        ...                           | ...    | ...    |...\n",
    "\n",
    "    selected_experiment_id: str\n",
    "        Experiment id selected as template\n",
    "\n",
    "    sample_id_colname: str\n",
    "        Column header that contains sample id that maps expression data and metadata\n",
    "\n",
    "    NN_architecture: str\n",
    "        Name of neural network architecture to use.\n",
    "        Format 'NN_<intermediate layer>_<latent layer>'\n",
    "\n",
    "    dataset_name: str\n",
    "        Name for analysis directory. Either \"Human\" or \"Pseudomonas\"\n",
    "\n",
    "    scaler: minmax model\n",
    "        Model used to transform data into a different range\n",
    "\n",
    "    local_dir: str\n",
    "        Parent directory on local machine to store intermediate results\n",
    "\n",
    "    base_dir: str\n",
    "        Root directory containing analysis subdirectories\n",
    "\n",
    "    run: int\n",
    "        Simulation run\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    simulated_data_file: str\n",
    "        File containing simulated gene expression data\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Files\n",
    "    NN_dir = os.path.join(base_dir, dataset_name, \"models\", NN_architecture)\n",
    "    latent_dim = NN_architecture.split(\"_\")[-1]\n",
    "\n",
    "    model_encoder_file = glob.glob(os.path.join(NN_dir, \"*_encoder_model.h5\"))[0]\n",
    "\n",
    "    weights_encoder_file = glob.glob(os.path.join(NN_dir, \"*_encoder_weights.h5\"))[0]\n",
    "\n",
    "    model_decoder_file = glob.glob(os.path.join(NN_dir, \"*_decoder_model.h5\"))[0]\n",
    "\n",
    "    weights_decoder_file = glob.glob(os.path.join(NN_dir, \"*_decoder_weights.h5\"))[0]\n",
    "\n",
    "    # Load saved models\n",
    "    loaded_model = load_model(model_encoder_file, compile=False)\n",
    "    loaded_decode_model = load_model(model_decoder_file, compile=False)\n",
    "\n",
    "    loaded_model.load_weights(weights_encoder_file)\n",
    "    loaded_decode_model.load_weights(weights_decoder_file)\n",
    "\n",
    "    # Read data\n",
    "    normalized_data = pd.read_csv(normalized_data_file, header=0, sep=\"\\t\", index_col=0)\n",
    "\n",
    "    # Get corresponding sample ids\n",
    "    sample_ids = get_sample_ids(\n",
    "        selected_experiment_id, metadata_filename, sample_id_colname\n",
    "    )\n",
    "\n",
    "    # Gene expression data for selected samples\n",
    "    selected_data_df = normalized_data.loc[sample_ids]\n",
    "\n",
    "    # Encode selected experiment into latent space\n",
    "    data_encoded = loaded_model.predict_on_batch(selected_data_df)\n",
    "    data_encoded_df = pd.DataFrame(data_encoded, index=selected_data_df.index)\n",
    "\n",
    "    # Get centroid of original data\n",
    "    centroid = data_encoded_df.mean(axis=0)\n",
    "\n",
    "    # Add individual vectors(centroid, sample point) to new_centroid\n",
    "\n",
    "    # Encode original gene expression data into latent space\n",
    "    data_encoded_all = loaded_model.predict_on_batch(normalized_data)\n",
    "    data_encoded_all_df = pd.DataFrame(data_encoded_all, index=normalized_data.index)\n",
    "\n",
    "    data_encoded_all_df.head()\n",
    "\n",
    "    # Find a new location in the latent space by sampling from the latent space\n",
    "    encoded_means = data_encoded_all_df.mean(axis=0)\n",
    "    encoded_stds = data_encoded_all_df.std(axis=0)\n",
    "\n",
    "    latent_dim = int(latent_dim)\n",
    "    new_centroid = np.zeros(latent_dim)\n",
    "\n",
    "    for j in range(latent_dim):\n",
    "        new_centroid[j] = np.random.normal(encoded_means[j], encoded_stds[j])\n",
    "\n",
    "    shift_vec_df = new_centroid - centroid\n",
    "    # print(shift_vec_df)\n",
    "\n",
    "    simulated_data_encoded_df = data_encoded_df.apply(\n",
    "        lambda x: x + shift_vec_df, axis=1\n",
    "    )\n",
    "\n",
    "    # Decode simulated data into raw gene space\n",
    "    simulated_data_decoded = loaded_decode_model.predict_on_batch(\n",
    "        simulated_data_encoded_df\n",
    "    )\n",
    "\n",
    "    simulated_data_decoded_df = pd.DataFrame(\n",
    "        simulated_data_decoded,\n",
    "        index=simulated_data_encoded_df.index,\n",
    "        columns=selected_data_df.columns,\n",
    "    )\n",
    "\n",
    "    # Un-normalize the data in order to run DE analysis downstream\n",
    "    simulated_data_scaled = scaler.inverse_transform(simulated_data_decoded_df)\n",
    "\n",
    "    simulated_data_scaled_df = pd.DataFrame(\n",
    "        simulated_data_scaled,\n",
    "        columns=simulated_data_decoded_df.columns,\n",
    "        index=simulated_data_decoded_df.index,\n",
    "    )\n",
    "\n",
    "    # Save template data for visualization validation\n",
    "    test_file = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        \"template_normalized_data_\" + selected_experiment_id + \"_test.txt\",\n",
    "    )\n",
    "\n",
    "    selected_data_df.to_csv(test_file, float_format=\"%.3f\", sep=\"\\t\")\n",
    "\n",
    "    # Save\n",
    "    out_file = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        \"selected_simulated_data_\" + selected_experiment_id + \"_\" + str(run) + \".txt\",\n",
    "    )\n",
    "\n",
    "    simulated_data_scaled_df.to_csv(out_file, float_format=\"%.3f\", sep=\"\\t\")\n",
    "\n",
    "    out_encoded_file = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        f\"selected_simulated_encoded_data_{selected_experiment_id}_{run}.txt\",\n",
    "    )\n",
    "\n",
    "    simulated_data_encoded_df.to_csv(out_encoded_file, float_format=\"%.3f\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate experiments using selected template experiment\n",
    "\n",
    "Workflow:\n",
    "1. Get the gene expression data for the selected template experiment\n",
    "2. Encode this experiment into a latent space using the trained VAE model\n",
    "3. Linearly shift the encoded template experiment in the latent space\n",
    "4. Decode the samples. This results in a new experiment\n",
    "5. Repeat steps 1-4 to get multiple simulated experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata file with grouping assignments for samples\n",
    "metadata_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", \"experiment_sample_annotations.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Simulate multiple experiments\n",
    "# This step creates the following files in \"<local_dir>/pseudo_experiment/\" directory:\n",
    "#   - selected_simulated_data_SRP012656_<n>.txt\n",
    "#   - selected_simulated_encoded_data_SRP012656_<n>.txt\n",
    "#   - template_normalized_data_SRP012656_test.txt\n",
    "# in which \"<n>\" is an integer in the range of [0, num_runs-1]\n",
    "os.makedirs(os.path.join(local_dir, \"pseudo_experiment\"), exist_ok=True)\n",
    "for run_id in range(num_runs):\n",
    "    shift_template_experiment_with_metadatafile(\n",
    "        normalized_compendium_filename,\n",
    "        project_id,\n",
    "        metadata_col_id,\n",
    "        NN_architecture,\n",
    "        dataset_name,\n",
    "        scaler,\n",
    "        local_dir,\n",
    "        base_dir,\n",
    "        run_id,\n",
    "        metadata_filename,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undo log transformation...\n",
    "# CHeck that template is also in log or unlogged form\n",
    "# Or log transform mapped_template instead\n",
    "mapped_template = pd.read_csv(mapped_template_filename, sep=\"\\t\", index_col=0, header=0)\n",
    "\n",
    "mapped_template_transform = (\n",
    "    np.log10(mapped_template).replace(-np.inf, 0.0).replace(np.nan, 0.0)\n",
    ")\n",
    "\n",
    "mapped_template_transform.to_csv(mapped_template_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process template and simulated experiments\n",
    "\n",
    "* Remove samples not required for comparison. Since this experiment contains multiple conditions (i.e. estradiol vs EtOH at 12, 24, and 48 hrs are each considered a different comparison) being tested, we will only include those samples within the same condition.\n",
    "* Make sure ordering of samples matches metadata for proper comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n",
      "sample ids are ordered correctly\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(sample_id_metadata_filename):\n",
    "    sample_id_metadata_filename = None\n",
    "\n",
    "stats.process_samples_for_limma(\n",
    "    mapped_template_filename,\n",
    "    grp_metadata_filename,\n",
    "    processed_template_filename,\n",
    "    sample_id_metadata_filename,\n",
    ")\n",
    "\n",
    "for i in range(num_runs):\n",
    "    simulated_filename = os.path.join(\n",
    "        local_dir, \"pseudo_experiment\", f\"selected_simulated_data_{project_id}_{i}.txt\"\n",
    "    )\n",
    "    out_simulated_filename = os.path.join(\n",
    "        local_dir,\n",
    "        \"pseudo_experiment\",\n",
    "        f\"selected_simulated_data_{project_id}_{i}_processed.txt\",\n",
    "    )\n",
    "    stats.process_samples_for_limma(\n",
    "        simulated_filename,\n",
    "        grp_metadata_filename,\n",
    "        out_simulated_filename,\n",
    "        sample_id_metadata_filename,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differential expression analysis\n",
    "\n",
    "The gene expression dataset is array-based so we will use Limma in this case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subdirectory: \"<local_dir>/DE_stats/\"\n",
    "os.makedirs(os.path.join(local_dir, \"DE_stats\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: S4Vectors\n",
      "\n",
      "R[write to console]: Loading required package: stats4\n",
      "\n",
      "R[write to console]: Loading required package: BiocGenerics\n",
      "\n",
      "R[write to console]: Loading required package: parallel\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘BiocGenerics’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:parallel’:\n",
      "\n",
      "    clusterApply, clusterApplyLB, clusterCall, clusterEvalQ,\n",
      "    clusterExport, clusterMap, parApply, parCapply, parLapply,\n",
      "    parLapplyLB, parRapply, parSapply, parSapplyLB\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:limma’:\n",
      "\n",
      "    plotMA\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    IQR, mad, sd, var, xtabs\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    anyDuplicated, append, as.data.frame, basename, cbind, colnames,\n",
      "    dirname, do.call, duplicated, eval, evalq, Filter, Find, get, grep,\n",
      "    grepl, intersect, is.unsorted, lapply, Map, mapply, match, mget,\n",
      "    order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank,\n",
      "    rbind, Reduce, rownames, sapply, setdiff, sort, table, tapply,\n",
      "    union, unique, unsplit, which, which.max, which.min\n",
      "\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘S4Vectors’\n",
      "\n",
      "\n",
      "R[write to console]: The following object is masked from ‘package:base’:\n",
      "\n",
      "    expand.grid\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: IRanges\n",
      "\n",
      "R[write to console]: Loading required package: GenomicRanges\n",
      "\n",
      "R[write to console]: Loading required package: GenomeInfoDb\n",
      "\n",
      "R[write to console]: Loading required package: SummarizedExperiment\n",
      "\n",
      "R[write to console]: Loading required package: Biobase\n",
      "\n",
      "R[write to console]: Welcome to Bioconductor\n",
      "\n",
      "    Vignettes contain introductory material; view with\n",
      "    'browseVignettes()'. To cite Bioconductor, see\n",
      "    'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: DelayedArray\n",
      "\n",
      "R[write to console]: Loading required package: matrixStats\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘matrixStats’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:Biobase’:\n",
      "\n",
      "    anyMissing, rowMedians\n",
      "\n",
      "\n",
      "R[write to console]: Loading required package: BiocParallel\n",
      "\n",
      "R[write to console]: \n",
      "Attaching package: ‘DelayedArray’\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:matrixStats’:\n",
      "\n",
      "    colMaxs, colMins, colRanges, rowMaxs, rowMins, rowRanges\n",
      "\n",
      "\n",
      "R[write to console]: The following objects are masked from ‘package:base’:\n",
      "\n",
      "    aperm, apply, rowsum\n",
      "\n",
      "\n",
      "R[write to console]: Error in metadata[, 1] : subscript out of bounds\n",
      "\n",
      "R[write to console]: In addition: \n",
      "R[write to console]: There were 12 warnings (use warnings() to see them)\n",
      "R[write to console]: \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in metadata[, 1] : subscript out of bounds\n"
     ]
    }
   ],
   "source": [
    "%%R -i metadata_filename -i project_id -i processed_template_filename -i local_dir -i base_dir\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/DE_analysis.R'))\n",
    "\n",
    "# File created: \"<local_dir>/DE_stats/DE_stats_template_data_SRP012656_real.txt\"\n",
    "get_DE_stats_limma(metadata_filename,\n",
    "                   project_id,\n",
    "                   processed_template_filename,\n",
    "                   \"template\",\n",
    "                   local_dir,\n",
    "                   \"real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'/home/alexandra/Documents/Data/Generic_expression_patterns_Crow/DE_stats/DE_stats_template_data_GSE10281_real.txt' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6eec7e056c74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m template_DE_stats = pd.read_csv(\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtemplate_DE_stats_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generic_expression/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generic_expression/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generic_expression/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generic_expression/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/generic_expression/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'/home/alexandra/Documents/Data/Generic_expression_patterns_Crow/DE_stats/DE_stats_template_data_GSE10281_real.txt' does not exist"
     ]
    }
   ],
   "source": [
    "# Check number of DEGs\n",
    "template_DE_stats_filename = os.path.join(\n",
    "    local_dir, \"DE_stats\", f\"DE_stats_template_data_{project_id}_real.txt\"\n",
    ")\n",
    "\n",
    "template_DE_stats = pd.read_csv(\n",
    "    template_DE_stats_filename, sep=\"\\t\", header=0, index_col=0\n",
    ")\n",
    "\n",
    "selected = template_DE_stats[\n",
    "    (template_DE_stats[\"adj.P.Val\"] < 0.05) & (abs(template_DE_stats[\"logFC\"]) > 1)\n",
    "]\n",
    "print(selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Error in metadata[, 1] : subscript out of bounds\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in metadata[, 1] : subscript out of bounds\n"
     ]
    }
   ],
   "source": [
    "%%R -i metadata_filename -i project_id -i base_dir -i local_dir -i num_runs\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/DE_analysis.R'))\n",
    "\n",
    "# Files created: \"<local_dir>/DE_stats/DE_stats_simulated_data_SRP012656_<n>.txt\"\n",
    "for (i in 0:(num_runs-1)){\n",
    "    simulated_data_filename <- paste(local_dir,\n",
    "                                     \"pseudo_experiment/selected_simulated_data_\",\n",
    "                                     project_id,\n",
    "                                     \"_\",\n",
    "                                     i,\n",
    "                                     \".txt\",\n",
    "                                     sep = \"\")\n",
    "\n",
    "    get_DE_stats_limma(metadata_filename,\n",
    "                       project_id,\n",
    "                       simulated_data_filename,\n",
    "                       \"simulated\",\n",
    "                       local_dir,\n",
    "                       i)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_type = \"DE\"\n",
    "template_DE_stats, simulated_DE_summary_stats = ranking.process_and_rank_genes_pathways(\n",
    "    template_DE_stats_filename,\n",
    "    local_dir,\n",
    "    num_runs,\n",
    "    project_id,\n",
    "    analysis_type,\n",
    "    col_to_rank_genes,\n",
    "    logFC_name,\n",
    "    pvalue_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "summary_gene_ranks = ranking.generate_summary_table(\n",
    "    template_DE_stats_filename,\n",
    "    template_DE_stats,\n",
    "    simulated_DE_summary_stats,\n",
    "    col_to_rank_genes,\n",
    "    local_dir,\n",
    "    \"gene\",\n",
    "    params,\n",
    ")\n",
    "\n",
    "summary_gene_ranks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is an NaN values, there should not be\n",
    "summary_gene_ranks.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `gene_summary_fielname`\n",
    "summary_gene_ranks.to_csv(gene_summary_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare gene ranking\n",
    "Studies have found that some genes are more likely to be differentially expressed even across a wide range of experimental designs. These *generic genes* are not necessarily specific to the biological process being studied but instead represent a more systematic change.\n",
    "\n",
    "We want to compare the ability to detect these generic genes using our method vs those found by [Crow et. al. publication](https://www.pnas.org/content/pnas/116/13/6491.full.pdf). Their genes are ranked 0 = not commonly DE; 1 = commonly DE. Genes were ranked by the number differentially expressed gene sets a gene appeared in across 600 experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get generic genes identified by Crow et. al.\n",
    "DE_prior_filename = params[\"reference_gene_filename\"]\n",
    "ref_gene_col = params[\"reference_gene_name_col\"]\n",
    "ref_rank_col = params[\"reference_rank_col\"]\n",
    "\n",
    "figure_filename = f\"gene_ranking_{col_to_rank_genes}.svg\"\n",
    "\n",
    "corr, shared_ranking = ranking.compare_gene_ranking(\n",
    "    summary_gene_ranks, DE_prior_filename, ref_gene_col, ref_rank_col, figure_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypergeometric test:\n",
    "\n",
    "Given N number of genes with K common genes in Crow et al. SOPHIE identifies n genes as being common. What is the probability that k of the genes identified by SOPHIE are also common in Crow et al.? What is the probability of drawing k or more concordant genes?\n",
    "\n",
    "This was a way for us to quantify the correlation between SOPHIE and Crow et al common findings, since the correlation coefficient wasn't very convincing since we're considering all genes in addition to the common ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_Crow_genes = shared_ranking.shape[0]\n",
    "num_generic_Crow_genes = shared_ranking.query(f\"{ref_rank_col}>=80.0\").shape[0]\n",
    "num_generic_SOPHIE_genes = shared_ranking[\n",
    "    shared_ranking[\"Percentile (simulated)\"] >= percentile_threshold\n",
    "].shape[0]\n",
    "num_concordant_generic_genes = shared_ranking[\n",
    "    (shared_ranking[ref_rank_col] >= percentile_threshold)\n",
    "    & (shared_ranking[\"Percentile (simulated)\"] >= percentile_threshold)\n",
    "].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_Crow_genes)\n",
    "print(num_generic_Crow_genes)\n",
    "print(num_generic_SOPHIE_genes)\n",
    "print(num_concordant_generic_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ss.hypergeom.sf(\n",
    "    num_concordant_generic_genes,\n",
    "    num_Crow_genes,\n",
    "    num_generic_Crow_genes,\n",
    "    num_generic_SOPHIE_genes,\n",
    ")\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Takeaway:**\n",
    "* Previously we compared gene ranks obtained from (recount2)-trained VAE model vs gene ranks obtained from manual curation using Crow et. al data. This [PR](https://github.com/ajlee21/generic-expression-patterns/blob/807377d76f63b6282c62255d7b160feb8585e0e2/human_analysis/2_identify_generic_genes_pathways.ipynb) shows that the correlation of gene ranks are very consistent.\n",
    "\n",
    "* Here we are comparing gene ranks obtained from a (Powers et. al.)-trained VAE model vs gene ranks obtained from manual curation using Crow et. al. Based on this correlation plot there is a high correlation between those very high and low ranked genes -- high correlation at the extremes but there is a lot of noise in the middle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GSEA\n",
    "**Goal:** To detect modest but coordinated changes in prespecified sets of related genes (i.e. those genes in the same pathway or share the same GO term).\n",
    "\n",
    "1. Rank all genes using DE association statistics.\n",
    "2. An enrichment score (ES) is defined as the maximum distance from the middle of the ranked list. Thus, the enrichment score indicates whether the genes contained in a gene set are clustered towards the beginning or the end of the ranked list (indicating a correlation with change in expression).\n",
    "3. Estimate the statistical significance of the ES by a phenotypic-based permutation test in order to produce a null distribution for the ES (i.e. scores based on permuted phenotype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"<local_dir>/GSEA_stats/\" subdirectory\n",
    "os.makedirs(os.path.join(local_dir, \"GSA_stats\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pathway data\n",
    "hallmark_DB_filename = params[\"pathway_DB_filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i base_dir -i template_DE_stats_filename -i hallmark_DB_filename -i statistic -i local_dir -o template_enriched_pathways\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/GSEA_analysis.R'))\n",
    "\n",
    "out_filename <- paste(local_dir,\n",
    "                     \"GSA_stats/GSEA_stats_template_data_\",\n",
    "                     project_id,\n",
    "                     \"_real.txt\",\n",
    "                     sep = \"\")\n",
    "\n",
    "template_enriched_pathways <- find_enriched_pathways(template_DE_stats_filename, hallmark_DB_filename, statistic)\n",
    "template_enriched_pathways <- as.data.frame(template_enriched_pathways[1:7])\n",
    "\n",
    "write.table(template_enriched_pathways, file = out_filename, row.names = F, sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(template_enriched_pathways.shape)\n",
    "template_enriched_pathways[template_enriched_pathways[\"padj\"] < 0.05].sort_values(\n",
    "    by=\"padj\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quick check:** Looks like enriched pathways are consistent with estradiol being estrogen hormone treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%R -i project_id -i local_dir -i hallmark_DB_filename -i num_runs -i statistic -i base_dir\n",
    "\n",
    "source(paste0(base_dir, '/generic_expression_patterns_modules/GSEA_analysis.R'))\n",
    "\n",
    "# New files created: \"<local_dir>/GSEA_stats/GSEA_stats_simulated_data_<project_id>_<n>.txt\"\n",
    "for (i in 0:(num_runs-1)) {\n",
    "    simulated_DE_stats_filename <- paste(local_dir,\n",
    "                                     \"DE_stats/DE_stats_simulated_data_\",\n",
    "                                     project_id,\n",
    "                                     \"_\",\n",
    "                                     i,\n",
    "                                     \".txt\",\n",
    "                                     sep = \"\")\n",
    "\n",
    "    out_filename <- paste(local_dir,\n",
    "                     \"GSA_stats/GSEA_stats_simulated_data_\",\n",
    "                     project_id,\n",
    "                     \"_\",\n",
    "                     i,\n",
    "                     \".txt\",\n",
    "                     sep = \"\")\n",
    "\n",
    "    enriched_pathways <- find_enriched_pathways(simulated_DE_stats_filename, hallmark_DB_filename, statistic)\n",
    "\n",
    "    write.table(as.data.frame(enriched_pathways[1:7]), file = out_filename, row.names = F, sep = \"\\t\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rank pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_type = \"GSA\"\n",
    "template_GSEA_stats_filename = os.path.join(\n",
    "    local_dir, \"GSA_stats\", f\"GSEA_stats_template_data_{project_id}_real.txt\"\n",
    ")\n",
    "(\n",
    "    template_GSEA_stats,\n",
    "    simulated_GSEA_summary_stats,\n",
    ") = ranking.process_and_rank_genes_pathways(\n",
    "    template_GSEA_stats_filename,\n",
    "    local_dir,\n",
    "    num_runs,\n",
    "    project_id,\n",
    "    analysis_type,\n",
    "    col_to_rank_pathways,\n",
    "    logFC_name,\n",
    "    pvalue_name,\n",
    "    \"GSEA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pathway summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create intermediate file: \"<local_dir>/gene_summary_table_<col_to_rank_pathways>.tsv\"\n",
    "summary_pathway_ranks = ranking.generate_summary_table(\n",
    "    template_GSEA_stats_filename,\n",
    "    template_GSEA_stats,\n",
    "    simulated_GSEA_summary_stats,\n",
    "    col_to_rank_pathways,\n",
    "    local_dir,\n",
    "    \"pathway\",\n",
    "    params,\n",
    ")\n",
    "\n",
    "summary_pathway_ranks.sort_values(by=\"Rank (simulated)\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create `pathway_summary_filename`\n",
    "summary_pathway_ranks.to_csv(pathway_summary_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare pathway ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Studies have found that there are some pathways (gene sets) that are more likely to be significantly enriched in DEGs across a wide range of experimental designs. These generic pathways are not necessarily specific to the biological process being studied but instead represents a more systematic change.\n",
    "\n",
    "We want to compare the ability to detect these generic pathways using our method vs those found by [Powers et. al.](https://www.biorxiv.org/content/10.1101/259440v1.full.pdf) publication.  We will use the `Hallmarks_qvalues_GSEAPreranked.csv` file from https://www.synapse.org/#!Synapse:syn11806255 as a reference. The file contains the q-value (adjusted p-value) for the test: given the enrichment score (ES) of the experiment is significant compared to the null distribution of enrichment scores, where the null set is generated from permuted gene sets. For each gene set (pathway) they calculate the q-value using this test.\n",
    "\n",
    "\n",
    "To get a `reference ranking`, we calculate the fraction of experiments that a given pathway was significant (q-value <0.05) and use this rank pathways. `Our ranking` is to rank pathways based on the median q-value across the simulated experiments. We can then compare `our ranking` versus the `reference ranking.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Powers et. al. results file\n",
    "powers_rank_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", \"Hallmarks_qvalues_GSEAPreranked.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Powers et. al. data\n",
    "# This file contains qvalue results for hallmark pathways across ~400 experiments\n",
    "powers_rank_df = pd.read_csv(powers_rank_filename, header=0, index_col=0)\n",
    "powers_rank_df.drop([\"Category\"], axis=1, inplace=True)\n",
    "print(powers_rank_df.shape)\n",
    "powers_rank_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count the number of experiments where a given pathway was found to be enriched (qvalue < 0.05)\n",
    "total_num_experiments = powers_rank_df.shape[1]\n",
    "frac_enriched_pathways = (powers_rank_df < 0.05).sum(axis=1) / total_num_experiments\n",
    "\n",
    "# Rank pathways from 0-50, 50 indicating that the pathways was frequently enriched\n",
    "pathway_ranks = frac_enriched_pathways.rank()\n",
    "\n",
    "powers_rank_stats_df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Fraction enriched\": frac_enriched_pathways.values,\n",
    "        \"Powers Rank\": pathway_ranks.values,\n",
    "    },\n",
    "    index=powers_rank_df.index,\n",
    ")\n",
    "powers_rank_stats_df.sort_values(by=\"Powers Rank\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reference file for input into comparison\n",
    "powers_rank_processed_filename = os.path.join(\n",
    "    base_dir,\n",
    "    dataset_name,\n",
    "    \"data\",\n",
    "    \"metadata\",\n",
    "    \"Hallmarks_qvalues_GSEAPreranked_processed.tsv\",\n",
    ")\n",
    "\n",
    "powers_rank_stats_df.to_csv(\n",
    "    powers_rank_processed_filename,\n",
    "    sep=\"\\t\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure_filename = f\"pathway_ranking_{col_to_rank_pathways}.svg\"\n",
    "\n",
    "ranking.compare_pathway_ranking(\n",
    "    summary_pathway_ranks, powers_rank_processed_filename, figure_filename\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our method ranked pathways using median adjusted p-value score across simulated experiments.\n",
    "* Powers et. al. ranked pathways based on the fraction of experiments they had adjusted p-value < 0.05.\n",
    "\n",
    "**Takeaway:**\n",
    "* Previously we compared pathway ranks obtained from (recount2)-trained VAE model vs pathway ranking based on manual curation using Powers et. al. This [PR](https://github.com/ajlee21/generic-expression-patterns/blob/807377d76f63b6282c62255d7b160feb8585e0e2/human_analysis/2_identify_generic_genes_pathways.ipynb) shows that there was no correlation.\n",
    "\n",
    "* Here we validated that our analysis pipeline is working correctly by comparing pathway ranks obtained from a (Powers et. al.)-trained VAE model vs pathway ranking based on manual curation using Powers et. al datasets. We expect to see a high correlation between pathway ranks given that we are using the same training dataset. Indeed that is what we find"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "\n",
    "* We find relatively similar generic genes using our simulation approach (i.e. VAE model trained on a cancer-specific dataset, Powers et. al.) compared to generic genes found from real general experiments from Crow et. al. These generic genes are not *that* context-specific at the extremes.\n",
    "\n",
    "* We found very different generic pathways training using our simulation approach trained on a general dataset (recount2) compared to generic pathways found from real cancer-specific experiments from Powers et. al. See [analysis](../human_general_analysis/2_identify_generic_genes_pathways.ipynb). But we get very similar generic pathways using our simulation approach trained on a cancer-specific dataset (Powers et. al.) compared with generic pathways found from cancer-specific dataset (Powers et. al.). This indicates that generic pathways are more context specific.\n",
    "\n",
    "* Why would the context matter more for pathways as opposed to genes? One way to think about this is using this figure from a recent [preprint](https://www.biorxiv.org/content/10.1101/2020.07.30.228296v1).Information flows from a stimulation that activates proteins within pathways and these proteins regulate gene expression. Say we have a context specific signal, that changes the TF within some pathways, this eventually trickles down to changes in gene expression. So if we think about flow of information, measuring pathway activity (or pathway enrichment, etc) will be more sensitive to our context compared to measuring DE in individual genes. Since the genes are regulated as a group, you'd see coordinated changes in expression that are correlated with your condition but looking at the expression of individual genes you wouldn’t necessarily see this correlation with condition."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:generic_expression] *",
   "language": "python",
   "name": "conda-env-generic_expression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
