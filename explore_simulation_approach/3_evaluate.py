# ---
# jupyter:
#   jupytext:
#     formats: ipynb,py
#     text_representation:
#       extension: .py
#       format_name: light
#       format_version: '1.5'
#       jupytext_version: 1.9.1+dev
#   kernelspec:
#     display_name: Python [conda env:generic_expression] *
#     language: python
#     name: conda-env-generic_expression-py
# ---

# # Evaluation
#
# How often do regular differential expression analysis vs sophie prioritize the specific vs generic genes?
#
# 1. Simulate 1 template perturbation experiment using the technique above
# 2. Apply SOPHIE to get ranking of specific and generic genes based on their z-score.
# 3. Apply traditional DE analysis and get ranking of specific and generic genes based on their log fold change value
# 4. Compare the difference in ranking between specific and generic genes using SOPHIE vs traditional metrics.

# +
# %load_ext autoreload
# %autoreload 2
# %load_ext rpy2.ipython
# %matplotlib inline
import os
import glob
import pickle
import pandas as pd
import seaborn as sns
import numpy as np
import scipy
from keras.models import load_model
import matplotlib.pyplot as plt
from rpy2.robjects import pandas2ri
from ponyo import utils, train_vae_modules, simulate_expression_data
from generic_expression_patterns_modules import (
    process,
    new_experiment_process,
    stats,
    ranking,
)

np.random.seed(1)

# +
# Read in config variables
base_dir = os.path.abspath(os.path.join(os.getcwd(), "../"))

config_filename = "config_sophie_vs_trad.tsv"

params = utils.read_config(config_filename)

# +
# Load config params

# Local directory to store intermediate files
local_dir = params["local_dir"]

#
dataset_name = params["dataset_name"]

# File containing un-normalized template experiment
raw_template_filename = params["raw_template_filename"]

# Un-normalized compendium filename
raw_compendium_filename = params["raw_compendium_filename"]

# Normalized compendium filename
normalized_compendium_filename = params["normalized_compendium_filename"]

# ID for template experiment to be selected
project_id = params["project_id"]

# Number of simulated experiments to generate
num_runs = params["num_simulated"]

# Directory containing trained VAE model
vae_model_dir = params["vae_model_dir"]

# Size of the latent dimension
latent_dim = params["latent_dim"]

# Scaler transform used to scale compendium data into 0-1 range for training
scaler_filename = params["scaler_filename"]

# Which DE method to use
# We recommend that if data is RNA-seq then use DESeq2
# If data is microarray then use Limma
de_method = params["DE_method"]

# If using DE-seq, setting this parameter will
# remove genes below a certain threshold
count_threshold = params["count_threshold"]

# Metadata file that specifies which samples to keep for DE analysis (Optional)
template_process_samples_filename = params["template_process_samples_filename"]

# Metadata file that specifies sample grouping for DE analysis
template_DE_grouping_filename = params["template_DE_grouping_filename"]

# Statistic to use to rank genes or pathways by
col_to_rank_genes = params["rank_genes_by"]

# Pickle files saving specific and generic gene ids
template_specific_gene_ids_filename = params["template_specific_gene_ids_filename"]
generic_gene_ids_filename = "generic_gene_ids.pickle"

# +
# Files generated by this notebook

# File storing template experiment with gene ids mapped to compendium gene ids
mapped_template_filename = params["mapped_template_filename"]

# File storing normalized template experiment
normalized_template_filename = params["normalized_template_filename"]

# File storing processed template experiment,
# after samples have been selected for comparison in DE analysis
processed_template_filename = params["processed_template_filename"]

# Output summary file
output_filename = params["output_filename"]
# -

# Process template
new_experiment_process.process_template_experiment(
    raw_template_filename,
    raw_compendium_filename,
    scaler_filename,
    mapped_template_filename,
    normalized_template_filename,
)

# ## Quick check

# +
# Check that normalized and applying scaler generate the same data

normalized_template_filename = params["normalized_template_filename"]

normalized_template = pd.read_csv(
    normalized_template_filename, sep="\t", index_col=0, header=0
)
normalized_template.head(10)

# +
# Load scaler file
scaler_transform = pickle.load(open(scaler_filename, "rb"))

template_experiment = pd.read_csv(
    raw_template_filename, sep="\t", index_col=0, header=0
)

template_experiment_scaled = scaler_transform.transform(template_experiment)

template_experiment_scaled_df = pd.DataFrame(
    template_experiment_scaled,
    columns=template_experiment.columns,
    index=template_experiment.index,
)
template_experiment_scaled_df.head(10)
# -

# ## Simulate data

# +
# Simulate multiple experiments UPDATE COMMENT
# This step creates the following files in "<local_dir>/pseudo_experiment/" directory:
#   - selected_simulated_data_SRP012656_<n>.txt
#   - selected_simulated_encoded_data_SRP012656_<n>.txt
#   - template_normalized_data_SRP012656_test.txt
# in which "<n>" is an integer in the range of [0, num_runs-1]

# Update simulated dir
os.makedirs(os.path.join(local_dir, "pseudo_experiment"), exist_ok=True)

normalized_compendium = pd.read_csv(
    normalized_compendium_filename, header=0, sep="\t", index_col=0
)
normalized_template = pd.read_csv(
    normalized_template_filename, header=0, sep="\t", index_col=0
)
# ------------
# Update call when new version of ponyo
for run_id in range(num_runs):
    new_experiment_process.embed_shift_template_experiment(
        normalized_compendium,
        normalized_template,
        vae_model_dir,
        project_id,
        scaler_filename,
        local_dir,
        latent_dim,
        run_id,
    )
# -

# ## Quick check

# +
i = 0
simulated_encoded_filename = os.path.join(
    local_dir,
    "pseudo_experiment",
    f"selected_simulated_encoded_data_{project_id}_{i}.txt",
)

simulated_data_encoded_df = pd.read_csv(
    simulated_encoded_filename, sep="\t", index_col=0, header=0
)
simulated_data_encoded_df.head()
# -

simulated_filename = os.path.join(
    local_dir,
    "pseudo_experiment",
    f"selected_simulated_data_{project_id}_{i}.txt",
)
simulated_experiment = pd.read_csv(simulated_filename, sep="\t", index_col=0, header=0)

# +
simulated_experiment_scaled = scaler_transform.transform(simulated_experiment)

simulated_experiment_scaled_df = pd.DataFrame(
    simulated_experiment_scaled,
    columns=simulated_experiment.columns,
    index=simulated_experiment.index,
)

# +
# Files
model_encoder_filename = glob.glob(os.path.join(vae_model_dir, "*_encoder_model.h5"))[0]

weights_encoder_filename = glob.glob(
    os.path.join(vae_model_dir, "*_encoder_weights.h5")
)[0]

model_decoder_filename = glob.glob(os.path.join(vae_model_dir, "*_decoder_model.h5"))[0]

weights_decoder_filename = glob.glob(
    os.path.join(vae_model_dir, "*_decoder_weights.h5")
)[0]

# Load saved models
loaded_model = load_model(model_encoder_filename)
loaded_decode_model = load_model(model_decoder_filename)

loaded_model.load_weights(weights_encoder_filename)
loaded_decode_model.load_weights(weights_decoder_filename)
# -

# Encode simulated experiment into VAE space
# Since encoder and decorder are not symmetric, we cannot expect the above and below df to be the same
simulated_data_encoded = loaded_model.predict_on_batch(simulated_experiment_scaled_df)
simulated_data_encoded_df_take2 = pd.DataFrame(
    simulated_data_encoded, index=simulated_experiment_scaled_df.index
)
simulated_data_encoded_df_take2.head()

# ## SOPHIE

# +
## Update simulated dir
if not os.path.exists(template_process_samples_filename):
    template_process_samples_filename = None

if de_method == "deseq":
    # Process template data
    stats.process_samples_for_DESeq(
        raw_template_filename,
        template_DE_grouping_filename,
        processed_template_filename,
        count_threshold,
        template_process_samples_filename,
    )

    # Process simulated data
    for i in range(num_runs):
        simulated_filename = os.path.join(
            local_dir,
            "pseudo_experiment",
            f"selected_simulated_data_{project_id}_{i}.txt",
        )
        out_simulated_filename = os.path.join(
            local_dir,
            "pseudo_experiment",
            f"selected_simulated_data_{project_id}_{i}_processed.txt",
        )
        stats.process_samples_for_DESeq(
            simulated_filename,
            template_DE_grouping_filename,
            out_simulated_filename,
            count_threshold,
            template_process_samples_filename,
        )
else:
    stats.process_samples_for_limma(
        raw_template_filename,
        template_DE_grouping_filename,
        processed_template_filename,
        template_process_samples_filename,
    )

    for i in range(num_runs):
        simulated_filename = os.path.join(
            local_dir,
            "pseudo_experiment",
            f"selected_simulated_data_{project_id}_{i}.txt",
        )
        stats.process_samples_for_limma(
            simulated_filename,
            template_DE_grouping_filename,
            None,
            template_process_samples_filename,
        )
# -

# Create subdirectory: "<local_dir>/DE_stats/"
os.makedirs(os.path.join(local_dir, "DE_stats"), exist_ok=True)

# + magic_args="-i template_DE_grouping_filename -i project_id -i processed_template_filename -i local_dir -i base_dir -i de_method" language="R"
#
# source(paste0(base_dir, '/generic_expression_patterns_modules/DE_analysis.R'))
#
# # File created: "<local_dir>/DE_stats/DE_stats_template_data_<project_id>_real.txt"
# if (de_method == "deseq"){
#     get_DE_stats_DESeq(
#         template_DE_grouping_filename,
#         project_id,
#         processed_template_filename,
#         "template",
#         local_dir,
#         "real"
#     )
# }
# else{
#     get_DE_stats_limma(
#         template_DE_grouping_filename,
#         project_id,
#         processed_template_filename,
#         "template",
#         local_dir,
#         "real"
#     )
# }

# + magic_args="-i template_DE_grouping_filename -i project_id -i base_dir -i local_dir -i num_runs -i de_method" language="R"
#
# source(paste0(base_dir, '/generic_expression_patterns_modules/DE_analysis.R'))
#
# # Files created: "<local_dir>/DE_stats/DE_stats_simulated_data_<project_id>_<n>.txt"
# for (i in 0:(num_runs-1)){
#     simulated_data_filename <- paste(
#         local_dir,
#         "pseudo_experiment/selected_simulated_data_",
#         project_id,
#         "_",
#         i,
#         "_processed.txt",
#         sep = ""
#     )
#     if (de_method == "deseq"){
#         get_DE_stats_DESeq(
#             template_DE_grouping_filename,
#             project_id,
#             simulated_data_filename,
#             "simulated",
#             local_dir,
#             i
#             )
#     }
#     else {
#         get_DE_stats_limma(
#             template_DE_grouping_filename,
#             project_id,
#             simulated_data_filename,
#             "simulated",
#             local_dir,
#             i
#             )
#         }
#     }

# +
analysis_type = "DE"
template_DE_stats_filename = os.path.join(
    local_dir, "DE_stats", f"DE_stats_template_data_{project_id}_real.txt"
)

# Added
if de_method == "deseq":
    logFC_name = "log2FoldChange"
    pvalue_name = "padj"
else:
    logFC_name = "logFC"
    pvalue_name = "adj.P.Val"

template_DE_stats, simulated_DE_summary_stats = ranking.process_and_rank_genes_pathways(
    template_DE_stats_filename,
    local_dir,
    num_runs,
    project_id,
    analysis_type,
    col_to_rank_genes,
    logFC_name,
    pvalue_name,
)

# +
# Get summary table
summary_gene_ranks = ranking.generate_summary_table(
    template_DE_stats_filename,
    template_DE_stats,
    simulated_DE_summary_stats,
    col_to_rank_genes,
    local_dir,
    "gene",
    params,
)

summary_gene_ranks.sort_values(by="Z score", ascending=False).head(10)
# -

summary_gene_ranks_sorted = summary_gene_ranks.sort_values(
    by="Z score", ascending=False
)

# Add ranking based on Z-score
summary_gene_ranks_sorted["rank"] = summary_gene_ranks_sorted["Z score"].rank(
    ascending=True
)

summary_gene_ranks_sorted.head(10)

summary_gene_ranks_sorted[summary_gene_ranks_sorted["Z score"].isna()]

# ## Traditional DE

# + magic_args="-i template_DE_grouping_filename -i project_id -i processed_template_filename -i local_dir -i base_dir -i de_method" language="R"
#
# source(paste0(base_dir, '/generic_expression_patterns_modules/DE_analysis.R'))
#
# # File created: "<local_dir>/DE_stats/DE_stats_template_data_<project_id>_real.txt"
# if (de_method == "deseq"){
#     get_DE_stats_DESeq(
#         template_DE_grouping_filename,
#         project_id,
#         processed_template_filename,
#         "template",
#         local_dir,
#         "real"
#     )
# }
# else{
#     get_DE_stats_limma(
#         template_DE_grouping_filename,
#         project_id,
#         processed_template_filename,
#         "template",
#         local_dir,
#         "real"
#     )
# }

# +
# Load DE statistics file
trad_de_stats_filename = os.path.join(
    local_dir, "DE_stats", f"DE_stats_template_data_{project_id}_real.txt"
)

trad_de_stats = pd.read_csv(trad_de_stats_filename, sep="\t", index_col=0, header=0)
# -

# Sort by log fold change
trad_de_stats_sorted = trad_de_stats.sort_values(by="log2FoldChange", ascending=False)

# Add ranking based on log2FoldChange
trad_de_stats_sorted["rank"] = trad_de_stats_sorted["log2FoldChange"].rank(
    ascending=True
)

trad_de_stats_sorted.head(10)

trad_de_stats_sorted[trad_de_stats_sorted["log2FoldChange"].isna()]

# ## Compare
#
# Let's compare how the ranking of genes changes between SOPHIE and traditional methods. If SOPHIE was better able to distinguish between common vs specific genes then we would expect the ranking of specific genes to increase using SOPHIE and decrease for common genes.

# ### Clean up data for plotting

# Remove rows where the gene ranking is NaN due to the gene having a baseMean of 0
trad_na_rows = trad_de_stats_sorted[trad_de_stats_sorted["rank"].isna()].index
sophie_na_rows = summary_gene_ranks_sorted[
    summary_gene_ranks_sorted["rank"].isna()
].index

trad_de_stats_sorted_processed = trad_de_stats_sorted.drop(trad_na_rows)
summary_gene_ranks_sorted_processed = summary_gene_ranks_sorted.drop(sophie_na_rows)

print(trad_de_stats_sorted_processed.shape)
print(summary_gene_ranks_sorted_processed.shape)

# Get ranking
sophie_rank = summary_gene_ranks_sorted_processed["rank"].to_frame("SOPHIE rank")
trad_rank = trad_de_stats_sorted_processed["rank"].to_frame("Traditional rank")

# +
# Load pickled file
with open(template_specific_gene_ids_filename, "rb") as specific_fh:
    specific_gene_ids = pickle.load(specific_fh)

with open(generic_gene_ids_filename, "rb") as generic_fh:
    generic_gene_ids = pickle.load(generic_fh)
# -

# Get NA genes
all_gene_ids = summary_gene_ranks_sorted_processed.index
all_gene_ids_tmp = all_gene_ids.difference(specific_gene_ids)
na_gene_ids = all_gene_ids_tmp.difference(generic_gene_ids)

# Add label for gene type
# Note: There are some ranks that are NA because SOPHIE z-scores or traditional logFC
# (which the rank is based on) is NA if the gene has base level expression of 0.
sophie_rank["gene type"] = "NA"
sophie_rank.loc[specific_gene_ids, "gene type"] = "specific"
sophie_rank.loc[generic_gene_ids, "gene type"] = "common"

print(sophie_rank.shape)
sophie_rank.head()

print(trad_rank.shape)
trad_rank.head()

sophie_trad_rank = sophie_rank.merge(trad_rank, left_index=True, right_index=True)

sophie_trad_rank = sophie_trad_rank.reset_index()

print(sophie_trad_rank.shape)
sophie_trad_rank.head()

sophie_trad_rank_melt = pd.melt(
    sophie_trad_rank,
    id_vars=["index", "gene type"],
    value_vars=["SOPHIE rank", "Traditional rank"],
)

print(sophie_trad_rank_melt.shape)
sophie_trad_rank_melt.head()

sophie_trad_rank_melt[sophie_trad_rank_melt["gene type"] == "specific"]

# +
# Statistical test using Wilcoxon to determine if the ranking of common genes is changed
# using traditional vs SOPHIE. Similarly for specific genes
trad_common_ranks = sophie_trad_rank_melt.loc[
    (sophie_trad_rank_melt["gene type"] == "common")
    & (sophie_trad_rank_melt["variable"] == "Traditional rank"),
    "value",
]

sophie_common_ranks = sophie_trad_rank_melt.loc[
    (sophie_trad_rank_melt["gene type"] == "common")
    & (sophie_trad_rank_melt["variable"] == "SOPHIE rank"),
    "value",
]

scipy.stats.wilcoxon(x=trad_common_ranks, y=sophie_common_ranks, alternative="greater")

# +
trad_specific_ranks = sophie_trad_rank_melt.loc[
    (sophie_trad_rank_melt["gene type"] == "specific")
    & (sophie_trad_rank_melt["variable"] == "Traditional rank"),
    "value",
]

sophie_specific_ranks = sophie_trad_rank_melt.loc[
    (sophie_trad_rank_melt["gene type"] == "specific")
    & (sophie_trad_rank_melt["variable"] == "SOPHIE rank"),
    "value",
]

scipy.stats.wilcoxon(x=trad_specific_ranks, y=sophie_specific_ranks, alternative="less")

# +
fig_summary = sns.catplot(
    x="variable",
    y="value",
    data=sophie_trad_rank_melt,
    hue="gene type",
    join=True,
    palette=["#3c78d8ff", "#9569b4ff", "grey"],
    hue_order=["common", "specific", "NA"],
    order=["Traditional rank", "SOPHIE rank"],
    dodge=True,
    kind="point",
    legend=False,
)
plt.title("Summarized gene ranking", fontsize=16)
plt.xlabel("")
plt.ylabel("Gene ranking", fontsize=14)
plt.xticks(fontsize=14)
plt.legend(fontsize=12, loc=(1.0, 0.5))

fig_summary.savefig(
    "sophie_vs_trad_summary.svg",
    format="svg",
    bbox_inches="tight",
    transparent=True,
    pad_inches=0,
    dpi=300,
)

# +
fig_specific = sns.catplot(
    x="variable",
    y="value",
    data=sophie_trad_rank_melt[sophie_trad_rank_melt["gene type"] == "specific"],
    hue="index",
    join=True,
    color="#9569b4ff",
    order=["Traditional rank", "SOPHIE rank"],
    kind="point",
    legend=False,
)
plt.title("Specific gene ranking", fontsize=16)
plt.xlabel("")
plt.ylabel("Gene ranking", fontsize=14)
plt.xticks(fontsize=14)

fig_specific.savefig(
    "sophie_vs_trad_specific.svg",
    format="svg",
    bbox_inches="tight",
    transparent=True,
    pad_inches=0,
    dpi=300,
)

# +
fig_common = sns.catplot(
    x="variable",
    y="value",
    data=sophie_trad_rank_melt[sophie_trad_rank_melt["gene type"] == "common"],
    hue="index",
    join=True,
    color="#3c78d8ff",
    order=["Traditional rank", "SOPHIE rank"],
    kind="point",
    legend=False,
)
plt.title("Common gene ranking", fontsize=16)
plt.xlabel("")
plt.ylabel("Gene ranking", fontsize=14)
plt.xticks(fontsize=14)

fig_common.savefig(
    "sophie_vs_trad_common.svg",
    format="svg",
    bbox_inches="tight",
    transparent=True,
    pad_inches=0,
    dpi=300,
)
