{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process pseudomonas data\n",
    "This notebook does the following:\n",
    "\n",
    "1. Selects template experiment from the Pseudomonas compendium created from [Tan et. al.](https://msystems.asm.org/content/1/1/e00025-15)\n",
    "2. Normalizes the gene expression data from the Pseudomonas compendium\n",
    "3. Train VAE on the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:21: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "from ponyo import utils, train_vae_modules\n",
    "from generic_expression_patterns_modules import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/Documents/Repos/generic-expression-patterns/generic_expression_patterns_modules/process.py:57: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seeds to get reproducible VAE trained models\n",
    "process.set_all_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for data processing\n",
    "\n",
    "Most parameters are read from `config_filename`. We manually selected bioproject [GEOD-33245](https://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-33245/?s_sortby=col_8&s_sortorder=ascending), as the template experiment, which contains multiple different comparisons including WT vs *crc* mutants, WT vs *cbr* mutants in different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "# Read in config variables\n",
    "config_filename = os.path.abspath(\n",
    "    os.path.join(base_dir, \"configs\", \"config_pseudomonas_33245.tsv\")\n",
    ")\n",
    "\n",
    "params = utils.read_config(config_filename)\n",
    "\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params[\"dataset_name\"]\n",
    "\n",
    "# Column header containing sample ids\n",
    "metadata_colname = params['metadata_colname']\n",
    "\n",
    "# Template experiment ID\n",
    "project_id = params['project_id']\n",
    "\n",
    "# Output file: pickled list of shared genes(generated during gene ID mapping)\n",
    "shared_genes_filename = params['shared_genes_filename']\n",
    "\n",
    "# Output files of pseudomonas template experiment data\n",
    "raw_template_filename = params['raw_template_filename']\n",
    "#mapped_template_filename = params['mapped_template_filename']\n",
    "processed_template_filename = params['processed_template_filename']\n",
    "\n",
    "# Output files of pseudomonas compendium data\n",
    "raw_compendium_filename = params['raw_compendium_filename']\n",
    "processed_compendium_filename = params['processed_compendium_filename']\n",
    "normalized_compendium_filename = params['normalized_compendium_filename']\n",
    "\n",
    "# Output file: pickled scaler (generated during compendium normalization)\n",
    "scaler_filename = params['scaler_filename']\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "sample_id_metadata_filename = os.path.join(\n",
    "    base_dir,\n",
    "    dataset_name,\n",
    "    \"data\",\n",
    "    \"metadata\",\n",
    "    f\"{project_id}_process_samples.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transpose raw pseudomonas compendium and normalize it\n",
    "The compendium is from https://raw.githubusercontent.com/greenelab/adage/master/Data_collection_processing/Pa_compendium_02.22.2014.pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.process_raw_compendium_pseudomonas(\n",
    "    raw_compendium_filename,\n",
    "    processed_compendium_filename,\n",
    "    normalized_compendium_filename,\n",
    "    scaler_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw pseudomonas template experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "process.process_raw_template_pseudomonas(\n",
    "    processed_compendium_filename,\n",
    "    project_id,\n",
    "    dataset_name,\n",
    "    metadata_colname,\n",
    "    raw_template_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* We are training our VAE model using ALL the data in the compendium.  \n",
    "* The template experiment is using a subset of the samples in the real experiment and using those in the DE analysis in order to ensure the comparison of samples with consistent backgrounds (i.e. some experiments have samples with 3 different biological conditions and for now our statistical test is doing a binary comparison).\n",
    "* Simulated experiments are generated by shifting the template experiment (using ALL samples in the real experiment) in the latent space. Then dropping the samples to match the template experiment and perform DE analysis.\n",
    "\n",
    "\n",
    "So there is an inconsistency in the samples used to learn a low-dimensional representation and those used to calculate DE statistics. This inconsistency should not not change the simulated experiments since all samples in the template experiment are moved the same amount in the latent space. The only way for this inconsistency to effect the simulated experiments is if the low dimensional space is significantly different including all the experiment samples vs only including a subset. However, we believe that such few samples will likely not effect the space. Furthermore, the dataset used to train the VAE should be a general representation of gene expression patterns and shouldn't have to be include the template experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE directories if needed\n",
    "output_dirs = [\n",
    "    os.path.join(base_dir, dataset_name, \"models\"),\n",
    "    os.path.join(base_dir, dataset_name, \"logs\")\n",
    "]\n",
    "\n",
    "NN_architecture = params['NN_architecture']\n",
    "\n",
    "# Check if NN architecture directory exist otherwise create\n",
    "for each_dir in output_dirs:\n",
    "    sub_dir = os.path.join(each_dir, NN_architecture)\n",
    "    os.makedirs(sub_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train VAE on new compendium data\n",
    "train_vae_modules.train_vae(config_filename,\n",
    "                            normalized_compendium_filename)"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1592246126078,
   "trusted": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:generic_expression] *",
   "language": "python",
   "name": "conda-env-generic_expression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
