{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process pseudomonas data\n",
    "This notebook trains a VAE on the PAO1 and PA14 RNA-seq compendia to support the analysis in https://github.com/greenelab/core-accessory-interactome\n",
    "\n",
    "1. Selects template experiment from the compendium\n",
    "2. Normalizes the gene expression data from the RNA-seq Pseudomonas compendium\n",
    "3. Train VAE on the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:21: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/ponyo/helper_vae.py:25: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/matplotlib/__init__.py:886: MatplotlibDeprecationWarning: \n",
      "examples.directory is deprecated; in the future, examples will be found relative to the 'datapath' directory.\n",
      "  \"found relative to the 'datapath' directory.\".format(key))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "\n",
    "from ponyo import utils, train_vae_modules\n",
    "from generic_expression_patterns_modules import process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/Documents/Repos/generic-expression-patterns/generic_expression_patterns_modules/process.py:57: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seeds to get reproducible VAE trained models\n",
    "process.set_all_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set parameters for data processing\n",
    "\n",
    "Most parameters are read from `config_filename`. We manually selected bioproject [GEOD-33245](https://www.ebi.ac.uk/arrayexpress/experiments/E-GEOD-33245/?s_sortby=col_8&s_sortorder=ascending), as the template experiment, which contains multiple different comparisons including WT vs *crc* mutants, WT vs *cbr* mutants in different conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"../\"))\n",
    "\n",
    "# Read in config variables\n",
    "config_filename = os.path.abspath(\n",
    "    os.path.join(base_dir, \"configs\", \"config_pseudomonas_pa14_rnaseq.tsv\")\n",
    ")\n",
    "\n",
    "params = utils.read_config(config_filename)\n",
    "\n",
    "local_dir = params[\"local_dir\"]\n",
    "dataset_name = params[\"dataset_name\"]\n",
    "\n",
    "# Column header containing sample ids\n",
    "metadata_colname = params[\"metadata_colname\"]\n",
    "\n",
    "# Template experiment ID\n",
    "project_id = params[\"project_id\"]\n",
    "\n",
    "# Output file: pickled list of shared genes(generated during gene ID mapping)\n",
    "shared_genes_filename = params[\"shared_genes_filename\"]\n",
    "\n",
    "# Output files of pseudomonas template experiment data\n",
    "raw_template_filename = params[\"raw_template_filename\"]\n",
    "processed_template_filename = params[\"processed_template_filename\"]\n",
    "\n",
    "# Output files of pseudomonas compendium data\n",
    "# raw_compendium_filename = params['raw_compendium_filename']\n",
    "processed_compendium_filename = params[\"processed_compendium_filename\"]\n",
    "normalized_compendium_filename = params[\"normalized_compendium_filename\"]\n",
    "\n",
    "# Output file: pickled scaler (generated during compendium normalization)\n",
    "scaler_filename = params[\"scaler_filename\"]\n",
    "\n",
    "# Load metadata file with grouping assignments for samples\n",
    "sample_id_metadata_filename = os.path.join(\n",
    "    base_dir, dataset_name, \"data\", \"metadata\", f\"{project_id}_process_samples.tsv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize compendium\n",
    "The compendium is MR normalized, but here we will 0-1 normalize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: dataset contains 576 samples and 5891 genes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'process.process_raw_compendium_pseudomonas(\\n    raw_compendium_filename,\\n    processed_compendium_filename,\\n    normalized_compendium_filename,\\n    scaler_filename,\\n)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process.normalize_compendium(\n",
    "    processed_compendium_filename,\n",
    "    normalized_compendium_filename,\n",
    "    scaler_filename,\n",
    ")\n",
    "\"\"\"process.process_raw_compendium_pseudomonas(\n",
    "    raw_compendium_filename,\n",
    "    processed_compendium_filename,\n",
    "    normalized_compendium_filename,\n",
    "    scaler_filename,\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(normalized_compendium_filename, sep=\"\\t\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PA14_55610</th>\n",
       "      <th>PA14_55600</th>\n",
       "      <th>PA14_55590</th>\n",
       "      <th>PA14_55580</th>\n",
       "      <th>PA14_55570</th>\n",
       "      <th>PA14_55560</th>\n",
       "      <th>PA14_55550</th>\n",
       "      <th>PA14_55540</th>\n",
       "      <th>PA14_55530</th>\n",
       "      <th>PA14_55520</th>\n",
       "      <th>...</th>\n",
       "      <th>PA14_19205</th>\n",
       "      <th>PA14_17675</th>\n",
       "      <th>PA14_67975</th>\n",
       "      <th>PA14_36345</th>\n",
       "      <th>PA14_43405</th>\n",
       "      <th>PA14_38825</th>\n",
       "      <th>PA14_24245</th>\n",
       "      <th>PA14_28895</th>\n",
       "      <th>PA14_55117</th>\n",
       "      <th>PA14_59845</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ERX1477379</th>\n",
       "      <td>0.149</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.073</td>\n",
       "      <td>0.295</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERX1477380</th>\n",
       "      <td>0.134</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.082</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.225</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERX1477381</th>\n",
       "      <td>0.115</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.176</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.109</td>\n",
       "      <td>0.015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.245</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERX2174773</th>\n",
       "      <td>0.024</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.041</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.141</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.344</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ERX2174774</th>\n",
       "      <td>0.031</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PA14_55610  PA14_55600  PA14_55590  PA14_55580  PA14_55570  \\\n",
       "ERX1477379       0.149       0.015       0.004       0.071       0.084   \n",
       "ERX1477380       0.134       0.026       0.005       0.089       0.129   \n",
       "ERX1477381       0.115       0.047       0.027       0.108       0.176   \n",
       "ERX2174773       0.024       0.034       0.014       0.002       0.026   \n",
       "ERX2174774       0.031       0.025       0.014       0.001       0.021   \n",
       "\n",
       "            PA14_55560  PA14_55550  PA14_55540  PA14_55530  PA14_55520  \\\n",
       "ERX1477379       0.007       0.032       0.017       0.062       0.017   \n",
       "ERX1477380       0.009       0.030       0.029       0.105       0.029   \n",
       "ERX1477381       0.012       0.035       0.038       0.109       0.015   \n",
       "ERX2174773       0.003       0.008       0.003       0.153       0.041   \n",
       "ERX2174774       0.003       0.004       0.005       0.161       0.025   \n",
       "\n",
       "               ...      PA14_19205  PA14_17675  PA14_67975  PA14_36345  \\\n",
       "ERX1477379     ...           0.073       0.295       0.135       0.033   \n",
       "ERX1477380     ...           0.082       0.240       0.092       0.021   \n",
       "ERX1477381     ...           0.141       0.235       0.095       0.018   \n",
       "ERX2174773     ...           0.219       0.077       0.141       0.068   \n",
       "ERX2174774     ...           0.230       0.056       0.126       0.067   \n",
       "\n",
       "            PA14_43405  PA14_38825  PA14_24245  PA14_28895  PA14_55117  \\\n",
       "ERX1477379         0.0       0.008       0.201       0.160       0.074   \n",
       "ERX1477380         0.0       0.003       0.095       0.225       0.030   \n",
       "ERX1477381         0.0       0.002       0.087       0.245       0.023   \n",
       "ERX2174773         0.0       0.030       0.056       0.344       0.032   \n",
       "ERX2174774         0.0       0.034       0.059       0.456       0.030   \n",
       "\n",
       "            PA14_59845  \n",
       "ERX1477379       0.054  \n",
       "ERX1477380       0.087  \n",
       "ERX1477381       0.031  \n",
       "ERX2174773       0.043  \n",
       "ERX2174774       0.049  \n",
       "\n",
       "[5 rows x 5891 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw pseudomonas template experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to pull out the template experiment from the compendium in this environment's version of ponyo\n",
    "# doesn't allow us to pass in a metadata file and instead assumes a fixed set of metadata files.\n",
    "# To manually work around this, we will locally define the functions here\n",
    "def get_sample_ids_tmp(\n",
    "    metadata_filename, delimiter, experiment_colname, experiment_id, sample_id_colname\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns sample ids (found in gene expression df) associated with\n",
    "    a given list of experiment ids (found in the metadata)\n",
    "\n",
    "    Arguments\n",
    "    ----------\n",
    "    metadata_filename: str\n",
    "        Metadata file path. An example metadata file can be found\n",
    "        here: https://github.com/greenelab/ponyo/blob/master/human_tests/data/metadata/recount2_metadata.tsv\n",
    "\n",
    "    delimiter: str\n",
    "        Delimiter for metadata file\n",
    "\n",
    "    experiment_colname: str\n",
    "        Column header that contains the experiment ids\n",
    "\n",
    "    experiment_id: str\n",
    "        Experiment id selected to retrieve sample ids for\n",
    "\n",
    "    sample_id_colname: str\n",
    "        Column header that contains sample id that maps expression data\n",
    "        and metadata\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Read in metadata\n",
    "    metadata = pd.read_csv(metadata_filename, header=0, sep=delimiter, index_col=None)\n",
    "\n",
    "    # Set index column to experiment id column\n",
    "    metadata.set_index(experiment_colname, inplace=True)\n",
    "\n",
    "    # Select samples associated with experiment id\n",
    "    selected_metadata = metadata.loc[experiment_id]\n",
    "    sample_ids = list(selected_metadata[sample_id_colname])\n",
    "\n",
    "    return sample_ids\n",
    "\n",
    "\n",
    "def process_raw_template_pseudomonas_tmp(\n",
    "    processed_compendium_filename,\n",
    "    project_id,\n",
    "    metadata_filename,\n",
    "    metadata_delimiter,\n",
    "    experiment_colname,\n",
    "    metadata_colname,\n",
    "    raw_template_filename,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create processed pseudomonas template data file based on\n",
    "    processed compendium file (`compendium_filename`),\n",
    "    drop sample rows if needed, and save updated\n",
    "    template data on disk.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get sample ids associated with selected project id\n",
    "    sample_ids = get_sample_ids_tmp(\n",
    "        metadata_filename,\n",
    "        metadata_delimiter,\n",
    "        experiment_colname,\n",
    "        project_id,\n",
    "        metadata_colname,\n",
    "    )\n",
    "\n",
    "    # Get samples from experiment id\n",
    "    processed_compendium = pd.read_csv(\n",
    "        processed_compendium_filename, header=0, index_col=0, sep=\"\\t\"\n",
    "    )\n",
    "    template_data = processed_compendium.loc[sample_ids]\n",
    "\n",
    "    template_data.to_csv(raw_template_filename, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_filename = \"data/metadata/SraRunTable.csv\"\n",
    "\n",
    "process_raw_template_pseudomonas_tmp(\n",
    "    processed_compendium_filename,\n",
    "    project_id,\n",
    "    metadata_filename,\n",
    "    \",\",\n",
    "    \"SRA_study\",\n",
    "    metadata_colname,\n",
    "    raw_template_filename,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = pd.read_csv(raw_template_filename, sep=\"\\t\", index_col=0, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PA14_55610</th>\n",
       "      <th>PA14_55600</th>\n",
       "      <th>PA14_55590</th>\n",
       "      <th>PA14_55580</th>\n",
       "      <th>PA14_55570</th>\n",
       "      <th>PA14_55560</th>\n",
       "      <th>PA14_55550</th>\n",
       "      <th>PA14_55540</th>\n",
       "      <th>PA14_55530</th>\n",
       "      <th>PA14_55520</th>\n",
       "      <th>...</th>\n",
       "      <th>PA14_19205</th>\n",
       "      <th>PA14_17675</th>\n",
       "      <th>PA14_67975</th>\n",
       "      <th>PA14_36345</th>\n",
       "      <th>PA14_43405</th>\n",
       "      <th>PA14_38825</th>\n",
       "      <th>PA14_24245</th>\n",
       "      <th>PA14_28895</th>\n",
       "      <th>PA14_55117</th>\n",
       "      <th>PA14_59845</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRX1740204</th>\n",
       "      <td>179.103190</td>\n",
       "      <td>76.046134</td>\n",
       "      <td>33.867541</td>\n",
       "      <td>1142.769777</td>\n",
       "      <td>356.544170</td>\n",
       "      <td>104.303714</td>\n",
       "      <td>31.166448</td>\n",
       "      <td>85.188292</td>\n",
       "      <td>75.838358</td>\n",
       "      <td>5.402184</td>\n",
       "      <td>...</td>\n",
       "      <td>48.619660</td>\n",
       "      <td>19.738751</td>\n",
       "      <td>261.382614</td>\n",
       "      <td>275.719181</td>\n",
       "      <td>0.623329</td>\n",
       "      <td>56.515160</td>\n",
       "      <td>135.054610</td>\n",
       "      <td>156.871124</td>\n",
       "      <td>63.164002</td>\n",
       "      <td>261.382614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRX1740205</th>\n",
       "      <td>160.820796</td>\n",
       "      <td>65.859945</td>\n",
       "      <td>31.972706</td>\n",
       "      <td>1395.886215</td>\n",
       "      <td>435.939228</td>\n",
       "      <td>115.829263</td>\n",
       "      <td>37.333399</td>\n",
       "      <td>101.470264</td>\n",
       "      <td>58.201812</td>\n",
       "      <td>4.786333</td>\n",
       "      <td>...</td>\n",
       "      <td>45.757345</td>\n",
       "      <td>25.654746</td>\n",
       "      <td>389.798976</td>\n",
       "      <td>251.952580</td>\n",
       "      <td>0.957267</td>\n",
       "      <td>116.212170</td>\n",
       "      <td>125.593383</td>\n",
       "      <td>164.075502</td>\n",
       "      <td>58.776172</td>\n",
       "      <td>296.561205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRX1740206</th>\n",
       "      <td>156.853998</td>\n",
       "      <td>69.081551</td>\n",
       "      <td>34.540776</td>\n",
       "      <td>695.749907</td>\n",
       "      <td>207.394180</td>\n",
       "      <td>56.820323</td>\n",
       "      <td>20.634749</td>\n",
       "      <td>52.334508</td>\n",
       "      <td>55.325052</td>\n",
       "      <td>4.037234</td>\n",
       "      <td>...</td>\n",
       "      <td>38.877063</td>\n",
       "      <td>23.326238</td>\n",
       "      <td>253.897129</td>\n",
       "      <td>341.220995</td>\n",
       "      <td>1.644799</td>\n",
       "      <td>126.350456</td>\n",
       "      <td>133.826814</td>\n",
       "      <td>136.368776</td>\n",
       "      <td>56.521269</td>\n",
       "      <td>306.829746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRX1740207</th>\n",
       "      <td>230.669314</td>\n",
       "      <td>54.576966</td>\n",
       "      <td>20.524671</td>\n",
       "      <td>474.399781</td>\n",
       "      <td>174.692938</td>\n",
       "      <td>39.183463</td>\n",
       "      <td>15.393503</td>\n",
       "      <td>47.346684</td>\n",
       "      <td>74.635167</td>\n",
       "      <td>5.364403</td>\n",
       "      <td>...</td>\n",
       "      <td>20.058201</td>\n",
       "      <td>24.722899</td>\n",
       "      <td>173.060294</td>\n",
       "      <td>483.029473</td>\n",
       "      <td>0.466470</td>\n",
       "      <td>113.352160</td>\n",
       "      <td>197.083488</td>\n",
       "      <td>102.156885</td>\n",
       "      <td>72.069583</td>\n",
       "      <td>390.901688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRX1740208</th>\n",
       "      <td>199.661033</td>\n",
       "      <td>64.058640</td>\n",
       "      <td>32.725610</td>\n",
       "      <td>562.776041</td>\n",
       "      <td>169.372437</td>\n",
       "      <td>59.010541</td>\n",
       "      <td>19.147963</td>\n",
       "      <td>52.743935</td>\n",
       "      <td>86.165834</td>\n",
       "      <td>8.529547</td>\n",
       "      <td>...</td>\n",
       "      <td>27.677510</td>\n",
       "      <td>21.584977</td>\n",
       "      <td>165.890989</td>\n",
       "      <td>368.337180</td>\n",
       "      <td>1.218507</td>\n",
       "      <td>95.043526</td>\n",
       "      <td>143.435650</td>\n",
       "      <td>125.506194</td>\n",
       "      <td>71.717825</td>\n",
       "      <td>330.911616</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5891 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            PA14_55610  PA14_55600  PA14_55590   PA14_55580  PA14_55570  \\\n",
       "SRX1740204  179.103190   76.046134   33.867541  1142.769777  356.544170   \n",
       "SRX1740205  160.820796   65.859945   31.972706  1395.886215  435.939228   \n",
       "SRX1740206  156.853998   69.081551   34.540776   695.749907  207.394180   \n",
       "SRX1740207  230.669314   54.576966   20.524671   474.399781  174.692938   \n",
       "SRX1740208  199.661033   64.058640   32.725610   562.776041  169.372437   \n",
       "\n",
       "            PA14_55560  PA14_55550  PA14_55540  PA14_55530  PA14_55520  \\\n",
       "SRX1740204  104.303714   31.166448   85.188292   75.838358    5.402184   \n",
       "SRX1740205  115.829263   37.333399  101.470264   58.201812    4.786333   \n",
       "SRX1740206   56.820323   20.634749   52.334508   55.325052    4.037234   \n",
       "SRX1740207   39.183463   15.393503   47.346684   74.635167    5.364403   \n",
       "SRX1740208   59.010541   19.147963   52.743935   86.165834    8.529547   \n",
       "\n",
       "               ...      PA14_19205  PA14_17675  PA14_67975  PA14_36345  \\\n",
       "SRX1740204     ...       48.619660   19.738751  261.382614  275.719181   \n",
       "SRX1740205     ...       45.757345   25.654746  389.798976  251.952580   \n",
       "SRX1740206     ...       38.877063   23.326238  253.897129  341.220995   \n",
       "SRX1740207     ...       20.058201   24.722899  173.060294  483.029473   \n",
       "SRX1740208     ...       27.677510   21.584977  165.890989  368.337180   \n",
       "\n",
       "            PA14_43405  PA14_38825  PA14_24245  PA14_28895  PA14_55117  \\\n",
       "SRX1740204    0.623329   56.515160  135.054610  156.871124   63.164002   \n",
       "SRX1740205    0.957267  116.212170  125.593383  164.075502   58.776172   \n",
       "SRX1740206    1.644799  126.350456  133.826814  136.368776   56.521269   \n",
       "SRX1740207    0.466470  113.352160  197.083488  102.156885   72.069583   \n",
       "SRX1740208    1.218507   95.043526  143.435650  125.506194   71.717825   \n",
       "\n",
       "            PA14_59845  \n",
       "SRX1740204  261.382614  \n",
       "SRX1740205  296.561205  \n",
       "SRX1740206  306.829746  \n",
       "SRX1740207  390.901688  \n",
       "SRX1740208  330.911616  \n",
       "\n",
       "[5 rows x 5891 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 5891)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "* We are training our VAE model using ALL the data in the compendium.\n",
    "* The template experiment is using a subset of the samples in the real experiment and using those in the DE analysis in order to ensure the comparison of samples with consistent backgrounds (i.e. some experiments have samples with 3 different biological conditions and for now our statistical test is doing a binary comparison).\n",
    "* Simulated experiments are generated by shifting the template experiment (using ALL samples in the real experiment) in the latent space. Then dropping the samples to match the template experiment and perform DE analysis.\n",
    "\n",
    "\n",
    "So there is an inconsistency in the samples used to learn a low-dimensional representation and those used to calculate DE statistics. This inconsistency should not not change the simulated experiments since all samples in the template experiment are moved the same amount in the latent space. The only way for this inconsistency to effect the simulated experiments is if the low dimensional space is significantly different including all the experiment samples vs only including a subset. However, we believe that such few samples will likely not effect the space. Furthermore, the dataset used to train the VAE should be a general representation of gene expression patterns and shouldn't have to be include the template experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create VAE directories if needed\n",
    "output_dirs = [\n",
    "    os.path.join(base_dir, dataset_name, \"models\"),\n",
    "    os.path.join(base_dir, dataset_name, \"logs\"),\n",
    "]\n",
    "\n",
    "NN_architecture = params[\"NN_architecture\"]\n",
    "\n",
    "# Check if NN architecture directory exist otherwise create\n",
    "for each_dir in output_dirs:\n",
    "    sub_dir = os.path.join(each_dir, NN_architecture)\n",
    "    os.makedirs(sub_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dataset contains 576 samples and 5891 genes\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "tracking <tf.Variable 'Variable:0' shape=() dtype=float32> beta\n",
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/keras/engine/training_utils.py:819: UserWarning: Output custom_variational_layer_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to custom_variational_layer_1.\n",
      "  'be expecting any data to be passed to {0}.'.format(name))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alexandra/anaconda3/envs/generic_expression/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 432 samples, validate on 144 samples\n",
      "Epoch 1/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 2285.7304 - val_loss: 2066.2920\n",
      "Epoch 2/120\n",
      "432/432 [==============================] - 30s 71ms/step - loss: 2024.0859 - val_loss: 2042.5120\n",
      "Epoch 3/120\n",
      "432/432 [==============================] - 33s 76ms/step - loss: 2006.1307 - val_loss: 2010.2319\n",
      "Epoch 4/120\n",
      "432/432 [==============================] - 30s 71ms/step - loss: 1989.1777 - val_loss: 1980.5012\n",
      "Epoch 5/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1979.8081 - val_loss: 1953.4778\n",
      "Epoch 6/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1977.1945 - val_loss: 1955.3486\n",
      "Epoch 7/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1969.9221 - val_loss: 1953.2205\n",
      "Epoch 8/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1968.7558 - val_loss: 1942.5529\n",
      "Epoch 9/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1966.4880 - val_loss: 1936.0332\n",
      "Epoch 10/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1959.6169 - val_loss: 1927.6219\n",
      "Epoch 11/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1949.9319 - val_loss: 1926.7937\n",
      "Epoch 12/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1941.4900 - val_loss: 1922.3076\n",
      "Epoch 13/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1935.5427 - val_loss: 1912.4086\n",
      "Epoch 14/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1935.5136 - val_loss: 1914.7326\n",
      "Epoch 15/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1932.1206 - val_loss: 1915.2921\n",
      "Epoch 16/120\n",
      "432/432 [==============================] - 30s 68ms/step - loss: 1926.9278 - val_loss: 1908.7419\n",
      "Epoch 17/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1920.7499 - val_loss: 1903.2217\n",
      "Epoch 18/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1911.0261 - val_loss: 1896.7811\n",
      "Epoch 19/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1914.8162 - val_loss: 1895.6590\n",
      "Epoch 20/120\n",
      "432/432 [==============================] - 30s 68ms/step - loss: 1907.8438 - val_loss: 1904.0288\n",
      "Epoch 21/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1905.6471 - val_loss: 1898.7446\n",
      "Epoch 22/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1897.6015 - val_loss: 1891.3678\n",
      "Epoch 23/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1898.2309 - val_loss: 1892.3050\n",
      "Epoch 24/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1895.0015 - val_loss: 1894.0996\n",
      "Epoch 25/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1888.4253 - val_loss: 1879.0177\n",
      "Epoch 26/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1882.7172 - val_loss: 1882.6808\n",
      "Epoch 27/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1883.9906 - val_loss: 1880.6125\n",
      "Epoch 28/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1878.8569 - val_loss: 1879.3781\n",
      "Epoch 29/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1874.1494 - val_loss: 1881.1634\n",
      "Epoch 30/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1877.7660 - val_loss: 1872.0911\n",
      "Epoch 31/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1874.6033 - val_loss: 1867.9298\n",
      "Epoch 32/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1865.6681 - val_loss: 1871.5482\n",
      "Epoch 33/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1862.3257 - val_loss: 1860.6530\n",
      "Epoch 34/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1858.8706 - val_loss: 1867.9358\n",
      "Epoch 35/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1854.7511 - val_loss: 1861.6481\n",
      "Epoch 36/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1856.2545 - val_loss: 1858.8670\n",
      "Epoch 37/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1856.1974 - val_loss: 1859.0272\n",
      "Epoch 38/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1848.9017 - val_loss: 1854.9643\n",
      "Epoch 39/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1848.1447 - val_loss: 1859.3142\n",
      "Epoch 40/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1851.4504 - val_loss: 1857.2479\n",
      "Epoch 41/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1843.5782 - val_loss: 1848.4931\n",
      "Epoch 42/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1840.8433 - val_loss: 1846.3837\n",
      "Epoch 43/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1838.3829 - val_loss: 1848.0103\n",
      "Epoch 44/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1839.0409 - val_loss: 1850.5280\n",
      "Epoch 45/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1836.3277 - val_loss: 1851.3751\n",
      "Epoch 46/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1837.2572 - val_loss: 1847.2945\n",
      "Epoch 47/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1839.8660 - val_loss: 1850.2911\n",
      "Epoch 48/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1834.9347 - val_loss: 1842.7149\n",
      "Epoch 49/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1834.5452 - val_loss: 1844.7641\n",
      "Epoch 50/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1827.8075 - val_loss: 1845.2175\n",
      "Epoch 51/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1830.1987 - val_loss: 1844.7323\n",
      "Epoch 52/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1828.3727 - val_loss: 1842.2923\n",
      "Epoch 53/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1828.5992 - val_loss: 1841.3309\n",
      "Epoch 54/120\n",
      "432/432 [==============================] - 34s 79ms/step - loss: 1826.6858 - val_loss: 1840.7381\n",
      "Epoch 55/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1827.6821 - val_loss: 1839.1637\n",
      "Epoch 56/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1824.5408 - val_loss: 1832.8587\n",
      "Epoch 57/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1821.6518 - val_loss: 1833.5915\n",
      "Epoch 58/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1821.3865 - val_loss: 1836.4311\n",
      "Epoch 59/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1817.7316 - val_loss: 1838.1445\n",
      "Epoch 60/120\n",
      "432/432 [==============================] - 33s 76ms/step - loss: 1815.7956 - val_loss: 1832.0482\n",
      "Epoch 61/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1816.4772 - val_loss: 1830.6136\n",
      "Epoch 62/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1811.3276 - val_loss: 1830.2987\n",
      "Epoch 63/120\n",
      "432/432 [==============================] - 33s 75ms/step - loss: 1815.3131 - val_loss: 1832.2148\n",
      "Epoch 64/120\n",
      "432/432 [==============================] - 30s 69ms/step - loss: 1815.1150 - val_loss: 1834.2603\n",
      "Epoch 65/120\n",
      "432/432 [==============================] - 28s 65ms/step - loss: 1813.5302 - val_loss: 1829.8452\n",
      "Epoch 66/120\n",
      "432/432 [==============================] - 29s 67ms/step - loss: 1811.3956 - val_loss: 1829.1448\n",
      "Epoch 67/120\n",
      "432/432 [==============================] - 28s 65ms/step - loss: 1815.1535 - val_loss: 1830.9435\n",
      "Epoch 68/120\n",
      "432/432 [==============================] - 29s 68ms/step - loss: 1812.3217 - val_loss: 1827.2268\n",
      "Epoch 69/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1808.1408 - val_loss: 1825.6233\n",
      "Epoch 70/120\n",
      "432/432 [==============================] - 30s 70ms/step - loss: 1808.1292 - val_loss: 1825.1515\n",
      "Epoch 71/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1807.8504 - val_loss: 1828.9514\n",
      "Epoch 72/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1806.5747 - val_loss: 1826.8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1804.6576 - val_loss: 1825.8965\n",
      "Epoch 74/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1806.2761 - val_loss: 1823.9533\n",
      "Epoch 75/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1802.5206 - val_loss: 1826.5235\n",
      "Epoch 76/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1804.7679 - val_loss: 1831.8176\n",
      "Epoch 77/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1806.0745 - val_loss: 1821.6941\n",
      "Epoch 78/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1798.9530 - val_loss: 1826.5364\n",
      "Epoch 79/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1806.4466 - val_loss: 1823.8791\n",
      "Epoch 80/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1803.5540 - val_loss: 1825.0557\n",
      "Epoch 81/120\n",
      "432/432 [==============================] - 32s 74ms/step - loss: 1797.3092 - val_loss: 1822.6113\n",
      "Epoch 82/120\n",
      "432/432 [==============================] - 32s 73ms/step - loss: 1801.7733 - val_loss: 1825.1757\n",
      "Epoch 83/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1799.9719 - val_loss: 1824.9743\n",
      "Epoch 84/120\n",
      "432/432 [==============================] - 31s 71ms/step - loss: 1799.2713 - val_loss: 1823.7330\n",
      "Epoch 85/120\n",
      "432/432 [==============================] - 31s 72ms/step - loss: 1796.4536 - val_loss: 1817.1560\n",
      "Epoch 86/120\n",
      "432/432 [==============================] - 23s 53ms/step - loss: 1797.5662 - val_loss: 1818.9812\n",
      "Epoch 87/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1797.1863 - val_loss: 1818.9592\n",
      "Epoch 88/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1792.9954 - val_loss: 1822.1789\n",
      "Epoch 89/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1792.7458 - val_loss: 1814.6350\n",
      "Epoch 90/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1793.1941 - val_loss: 1818.3301\n",
      "Epoch 91/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1790.2540 - val_loss: 1815.5935\n",
      "Epoch 92/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1793.7288 - val_loss: 1815.5277\n",
      "Epoch 93/120\n",
      "432/432 [==============================] - 23s 53ms/step - loss: 1790.8599 - val_loss: 1816.3527\n",
      "Epoch 94/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1790.4536 - val_loss: 1813.2273\n",
      "Epoch 95/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1786.8011 - val_loss: 1818.6497\n",
      "Epoch 96/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1790.6214 - val_loss: 1816.1676\n",
      "Epoch 97/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1786.3133 - val_loss: 1812.9638\n",
      "Epoch 98/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1785.7257 - val_loss: 1810.3397\n",
      "Epoch 99/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1785.7741 - val_loss: 1816.5067\n",
      "Epoch 100/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1787.1937 - val_loss: 1814.6008\n",
      "Epoch 101/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1788.4456 - val_loss: 1813.6656\n",
      "Epoch 102/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1784.0084 - val_loss: 1816.0088\n",
      "Epoch 103/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1784.8813 - val_loss: 1816.2786\n",
      "Epoch 104/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1783.3322 - val_loss: 1809.4144\n",
      "Epoch 105/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1785.2198 - val_loss: 1812.4714\n",
      "Epoch 106/120\n",
      "432/432 [==============================] - 23s 53ms/step - loss: 1784.1719 - val_loss: 1815.4371\n",
      "Epoch 107/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1782.3254 - val_loss: 1812.8955\n",
      "Epoch 108/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1784.6037 - val_loss: 1814.2302\n",
      "Epoch 109/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1786.4530 - val_loss: 1811.2171\n",
      "Epoch 110/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1785.6369 - val_loss: 1811.5655\n",
      "Epoch 111/120\n",
      "432/432 [==============================] - 22s 51ms/step - loss: 1783.7067 - val_loss: 1814.4343\n",
      "Epoch 112/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1782.9033 - val_loss: 1814.9859\n",
      "Epoch 113/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1783.2347 - val_loss: 1814.2759\n",
      "Epoch 114/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1781.5316 - val_loss: 1810.4445\n",
      "Epoch 115/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1778.2701 - val_loss: 1812.6365\n",
      "Epoch 116/120\n",
      "432/432 [==============================] - 23s 52ms/step - loss: 1779.9083 - val_loss: 1810.5268\n",
      "Epoch 117/120\n",
      "432/432 [==============================] - 23s 53ms/step - loss: 1779.7303 - val_loss: 1815.5950\n",
      "Epoch 118/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1780.3267 - val_loss: 1811.5944\n",
      "Epoch 119/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1777.3175 - val_loss: 1807.2468\n",
      "Epoch 120/120\n",
      "432/432 [==============================] - 22s 52ms/step - loss: 1777.2581 - val_loss: 1812.1069\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train VAE on new compendium data\n",
    "train_vae_modules.train_vae(config_filename, normalized_compendium_filename)"
   ]
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1592246126078,
   "trusted": true
  },
  "jupytext": {
   "formats": "ipynb,py"
  },
  "kernelspec": {
   "display_name": "Python [conda env:generic_expression] *",
   "language": "python",
   "name": "conda-env-generic_expression-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
